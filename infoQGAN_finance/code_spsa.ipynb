{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from functools import reduce\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 금융 데이터를 yfinance로부터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "def get_stocks_datas(ticker_names: list[str], start_date, end_date):\n",
    "    # WARN: returns는 prices보다 길이가 1 작다.\n",
    "    prices = {}\n",
    "    returns = {}\n",
    "    for name in ticker_names:\n",
    "        data = yf.Ticker(name)\n",
    "        data = data.history(start=start_date, end=end_date, interval=\"1d\")\n",
    "        prices[name] = data['Close']\n",
    "        returns[name] = data['Close'].pct_change()[1:]\n",
    "    return prices, returns\n",
    "\n",
    "start_date = datetime.datetime(2010, 1, 1)\n",
    "end_date = datetime.datetime(2017, 12, 31)\n",
    "stock_prices, stock_returns = get_stocks_datas([\"AAPL\", \"MSFT\"], start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산점도 그리기\n",
    "plt.scatter(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values, alpha=0.5)\n",
    "plt.title(f'AAPL/MSFT daily returns')\n",
    "plt.xlabel('AAPL')\n",
    "plt.ylabel('MSFT')\n",
    "plt.xlim(-0.15, 0.15)\n",
    "plt.ylim(-0.15, 0.15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copula 변환/역변환 준비\n",
    "\n",
    "역변환은 기존 분포를 normal distribution이라 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import random\n",
    "\n",
    "def probability_integral_transform(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    n = len(x)\n",
    "    x_sorted = sorted([(x, i) for i, x in enumerate(x)])\n",
    "    y_sorted = sorted([(y, i) for i, y in enumerate(y)])\n",
    "    xx = np.zeros(n)\n",
    "    yy = np.zeros(n)\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        xx[x_sorted[i][1]] = i / n\n",
    "        yy[y_sorted[i][1]] = i / n\n",
    "        \n",
    "    return xx, yy\n",
    "\n",
    "def reverse_probability_integral_transform(x, y, x_mean, x_std, y_mean, y_std):\n",
    "    assert(len(x) == len(y))\n",
    "    n = len(x)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for i in range(n):\n",
    "        # 정규분포에서 면적이 x[i] 가 되는 z값\n",
    "        xx.append(norm.ppf(x[i], loc=x_mean, scale=x_std))\n",
    "        yy.append(norm.ppf(y[i], loc=y_mean, scale=y_std))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_x, copula_y = probability_integral_transform(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values)\n",
    "plt.scatter(copula_x, copula_y, s=20)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Copula space plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_distribution = np.column_stack((copula_x, copula_y))\n",
    "plt.scatter(target_distribution[:,0], target_distribution[:,1], s=2.0)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting torch device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_qubits = 6\n",
    "code_qubits = 1\n",
    "n_qubits = noise_qubits + code_qubits\n",
    "\n",
    "n_layers = 1\n",
    "print(\"n_qubits = {} n_layers = {}\".format(n_qubits, n_layers))\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "MINIBATCH_SIZE = 16\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits, shots=1) # 제너레이터 돌려서 값 뽑아내는데 쓰임. 이중 몇개 골라서 판별자도 학습함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 0.2\n",
    "\n",
    "def generator_init(generator_input):\n",
    "    for i in range(noise_qubits):\n",
    "        qml.Hadamard(wires=i)\n",
    "    for i in range(noise_qubits//2):\n",
    "        qml.CNOT(wires=[i, i+noise_qubits//2])\n",
    "\n",
    "def generator_layer(params):\n",
    "    for i in range(n_qubits-code_qubits):\n",
    "        qml.RZ(params[i][0], wires=i)\n",
    "        qml.RX(params[i][1], wires=i)\n",
    "        qml.RZ(params[i][2], wires=i)\n",
    "    \n",
    "    for i in range(n_qubits-code_qubits):\n",
    "        qml.CNOT(wires=[i, (i+1)%(n_qubits-code_qubits)])\n",
    "        qml.RX(params[i][3], wires=i)\n",
    "        qml.CNOT(wires=[i, (i+1)%(n_qubits-code_qubits)])\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def generator_circuit(params, generator_input):\n",
    "    generator_init(generator_input)\n",
    "    for param in params:\n",
    "        generator_layer(param)\n",
    "    return qml.sample(wires=range(n_qubits))\n",
    "\n",
    "\n",
    "def generator_forward(params, generator_input):\n",
    "    generator_output = [generator_circuit(params, single_in) for single_in in generator_input]\n",
    "    values = []\n",
    "    for output in generator_output:\n",
    "        gen_x = 0\n",
    "        gen_y = 0\n",
    "        for i in range(noise_qubits//2):\n",
    "            gen_x += (0.5**(i+1)) * output[i]\n",
    "        for i in range(noise_qubits//2, noise_qubits):\n",
    "            gen_y += (0.5**(i-noise_qubits//2+1)) * output[i]\n",
    "        gen_x += random.randint(0, (2**20)-1) / (2**23)\n",
    "        gen_y += random.randint(0, (2**20)-1) / (2**23)\n",
    "        values.append([gen_x, gen_y])\n",
    "    generator_output = torch.tensor(values) # (-1, 2) 차원\n",
    "    return generator_output\n",
    "\n",
    "\n",
    "def generator_cost_fn(params, generator_input, use_mine = False, _qmine = False):\n",
    "    code_input = generator_input[:, -code_qubits:] # 입력중에서 code만 뽑는다. (-1, code_qubits)\n",
    "\n",
    "    generator_output = generator_forward(params, generator_input) # 출력을 뽑아낸다\n",
    "    generator_output = generator_output.to(torch.float32) # (-1, output_qubits)\n",
    "    \n",
    "    disc_output = discriminator(generator_output) # 밑에 코드에서 정의됨\n",
    "    gan_loss = -torch.log(disc_output).mean()\n",
    "    \n",
    "    if use_mine:\n",
    "        pred_xy = mine(code_input, generator_output)\n",
    "        code_input_shuffle = code_input[torch.randperm(len(code_input))]\n",
    "        pred_x_y = mine(code_input_shuffle, generator_output)\n",
    "        mi = torch.mean(pred_xy) - torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        gan_loss -= coeff * mi\n",
    "\n",
    "    elif _qmine:\n",
    "        gan_loss += 0 # TODO: qmine loss 추가하기\n",
    "\n",
    "    return gan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LinearDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(len(x.shape) != 2):\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class LinearMine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMine, self).__init__()\n",
    "        H = 32\n",
    "        self.fc1 = nn.Linear(code_qubits, H)\n",
    "        self.fc2 = nn.Linear(2, H)\n",
    "        self.fc3 = nn.Linear(H, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h1 = F.relu(self.fc1(x)+self.fc2(y))\n",
    "        h2 = self.fc3(h1)\n",
    "        return h2\n",
    "\n",
    "disc_loss_fn = nn.BCELoss()\n",
    "def disc_cost_fn(real_input, fake_input, smoothing=False):\n",
    "\n",
    "    disc_real = discriminator(real_input)\n",
    "    disc_fake = discriminator(fake_input)\n",
    "\n",
    "    if smoothing:\n",
    "        real_label = real_label - 0.2*torch.rand(real_label.shape).to(device)\n",
    "    #print(\"disc debug하자 \",\"real = \", disc_real.mean().item(), disc_real.std().item(), \"fake = \", disc_fake.mean().item(), disc_fake.std().item())\n",
    "    #print(\"항별 값 = \", torch.log(disc_real).mean() , torch.log(1.0 - disc_fake).mean())\n",
    "    \n",
    "    #loss = -0.5 * (torch.log(disc_real).mean() + torch.log(1.0 - disc_fake).mean())\n",
    "\n",
    "    real_label = torch.ones((real_input.shape[0], 1)).to(device)\n",
    "    fake_label = torch.zeros((fake_input.shape[0], 1)).to(device)\n",
    "    \n",
    "    a = disc_loss_fn(disc_real, real_label)\n",
    "    b = disc_loss_fn(disc_fake, fake_label)\n",
    "    return (a+b)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom spsa optimizer\n",
    "\n",
    "구현 오류 제보 환영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPSA_opt():\n",
    "    def __init__(self, a=0.008, c=0.01, n_iter = 5, gamma=0.101):\n",
    "        self.epoch = 1\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "        self.n_iter = n_iter\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def step(self):\n",
    "        self.epoch += 1\n",
    "    \n",
    "    def get_params(self):\n",
    "        # (a, c) tuple return\n",
    "        return self.a/self.epoch, self.c/(self.epoch**self.gamma)\n",
    "\n",
    "def spsa_step(params):\n",
    "    # 한 iter당 n_iter * 2 * MINIBATCH_SIZE 만큼 순회함\n",
    "    # 기본값 = 5 * 2 * 16 = 160\n",
    "    # return값: 평균 loss\n",
    "    loss_sum = 0\n",
    "    spsa_opt = SPSA_opt()\n",
    "    for i in range(spsa_opt.n_iter):\n",
    "        a, c = spsa_opt.get_params()\n",
    "        delta = np.random.choice([-1, 1], size=params.shape)\n",
    "        z = np.random.uniform(-1, 1, (MINIBATCH_SIZE, n_qubits))\n",
    "\n",
    "        loss_plus = generator_cost_fn(params + c * delta, z) # 실제론 shot=MINIBATCH_SIZE\n",
    "        loss_plus = loss_plus.detach().numpy()\n",
    "        loss_minus = generator_cost_fn(params - c * delta, z) # 실제론 shot=MINIBATCH_SIZE\n",
    "        loss_minus = loss_minus.detach().numpy()\n",
    "\n",
    "        g = (loss_plus - loss_minus)/(2*c*delta)\n",
    "        # print('param = ', params[0], 'delta =', (a*g)[0], 'aft =', (params-a*g)[0])\n",
    "        params -= a*g\n",
    "        loss_sum = loss_sum + (loss_plus + loss_minus)/2\n",
    "        spsa_opt.step()\n",
    "    \n",
    "    return params, loss_sum / spsa_opt.n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter shape:  torch.Size([1, 7, 4])\n"
     ]
    }
   ],
   "source": [
    "generator_params = Variable(torch.tensor(np.random.uniform(0, 2*np.pi, (n_layers, n_qubits, 4))))\n",
    "print(\"parameter shape: \", generator_params.shape)\n",
    "\n",
    "discriminator = LinearDiscriminator()\n",
    "mine = LinearMine()\n",
    "\n",
    "D_lr = 0.003\n",
    "M_lr = 1e-4\n",
    "use_mine = False\n",
    "use_qmine = False\n",
    "D_opt = torch.optim.Adam(discriminator.parameters(), lr=D_lr)\n",
    "M_opt = torch.optim.Adam(mine.parameters(), lr=M_lr)\n",
    "\n",
    "D_scheduler = torch.optim.lr_scheduler.StepLR(D_opt, step_size=30, gamma=0.85)\n",
    "M_scheduler = torch.optim.lr_scheduler.StepLR(M_opt, step_size=30, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "title = f'spsa19_{use_mine}'\n",
    "if not os.path.exists(f'result/{title}'):\n",
    "    os.makedirs(f'result/{title}')\n",
    "    \n",
    "with open(f'result/{title}/param.txt', 'w') as f:\n",
    "    f.write('D_lr = {}\\n'.format(D_lr))\n",
    "    f.write('M_lr = {}\\n'.format(M_lr))\n",
    "    f.write('D_scheduler: step={}, gamma={}\\n'.format(D_scheduler.step_size, D_scheduler.gamma))\n",
    "    f.write('M_scheduler: step={}, gamma={}\\n'.format(M_scheduler.step_size, M_scheduler.gamma))\n",
    "    f.write('coeff = {}\\n'.format(coeff))\n",
    "    f.write('use_mine = {}\\n'.format(use_mine))\n",
    "    f.write('use_qmine = {}\\n'.format(use_qmine))\n",
    "    f.write('n_qubits = {}\\n'.format(n_qubits))\n",
    "    f.write('noise_qubits = {}\\n'.format(noise_qubits))\n",
    "    f.write('code_qubits = {}\\n'.format(code_qubits))\n",
    "    f.write('n_layers = {}\\n'.format(n_layers))\n",
    "    f.write('param shape = {}\\n'.format(generator_params.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def visualize_output(gen_outputs, gen_codes, rev, title, rep, recorder):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plt.figure(figsize=(10 + 4 * code_qubits, 7))  # 전체 그림의 크기 지정\n",
    "    \n",
    "    plt.subplot(2, 2 + code_qubits, 1)\n",
    "    plt.title('Target distribution')\n",
    "    plt.scatter(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"], s=10,  alpha=0.2)\n",
    "    plt.xlim((-0.2, 0.2))\n",
    "    plt.ylim((-0.2, 0.2))\n",
    "    plt.grid()\n",
    "\n",
    "    # 역변환\n",
    "    rev_x, rev_y = rev\n",
    "    plt.subplot(2, 2 + code_qubits, 2)\n",
    "    plt.title('Epoch {0}'.format(rep))\n",
    "    plt.scatter(rev_x, rev_y, s=10,  alpha=0.2)\n",
    "    plt.xlim((-0.2, 0.2))\n",
    "    plt.ylim((-0.2, 0.2))\n",
    "    plt.grid()\n",
    "\n",
    "    for i in range(code_qubits):\n",
    "        plt.subplot(2, 2 + code_qubits, 3 + i)\n",
    "        plt.title('Epoch {0} code {1}'.format(rep, i))\n",
    "        plt.scatter(rev_x, rev_y, s=10, c=gen_codes[:, i], cmap='RdYlBu', alpha=0.2)\n",
    "        plt.xlim((-0.2, 0.2))\n",
    "        plt.ylim((-0.2, 0.2))\n",
    "        plt.colorbar()  # 색상 막대 추가\n",
    "        plt.grid()\n",
    "    \n",
    "    \n",
    "    plt.subplot(2, 2 + code_qubits, 3 + code_qubits)\n",
    "    plt.title('Target copula'.format(rep))\n",
    "    plt.scatter(copula_x, copula_y, s=10,  alpha=0.2)\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2, 2 + code_qubits, 4 + code_qubits)\n",
    "    plt.title('Epoch {0} copula'.format(rep))\n",
    "    plt.scatter(gen_outputs[:, 0], gen_outputs[:, 1], s=10,  alpha=0.2)\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "\n",
    "    for i in range(code_qubits):\n",
    "        plt.subplot(2, 2 + code_qubits, 5 + code_qubits + i)\n",
    "        plt.title('Epoch {0} code {1}'.format(rep, i))\n",
    "        plt.scatter(gen_outputs[:, 0], gen_outputs[:, 1], s=10, c=gen_codes[:, i], cmap='RdYlBu', alpha=0.2)\n",
    "        plt.xlim((0, 1))\n",
    "        plt.ylim((0, 1))\n",
    "        plt.colorbar()  # 색상 막대 추가\n",
    "        plt.grid()\n",
    "\n",
    "    plt.savefig(f'result/{title}/{rep}.png', dpi=300)\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Epoch {0} code-axis corr'.format(rep))\n",
    "    for i in range(code_qubits):\n",
    "        plt.plot(recorder[f'code{i}-x'], label=f'code{i}-x', marker='o')\n",
    "        plt.plot(recorder[f'code{i}-y'], label=f'code{i}-y', marker='o')\n",
    "        plt.plot(recorder['mi'], label='mi', marker='o')\n",
    "        plt.plot(recorder['d_loss'], label='d_loss', marker='o')\n",
    "        plt.plot(recorder['g_loss'], label='g_loss', marker='o')\n",
    "        plt.plot(recorder['corr'], label='corr', marker='o')\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('correlation')\n",
    "    plt.ylim(-1, 2)\n",
    "    plt.title(f'code - axis corr graph (rep={rep})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'result/{title}/corr_{rep}.png', dpi=300)\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Epoch {0} KS stastics'.format(rep))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recorder['D_ks'], label='D_ks', marker='o')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recorder['p-value'], label='p-value', marker='o')\n",
    "    plt.yscale(\"log\", base=10)  # 로그 스케일로 설정\n",
    "    plt.legend()\n",
    "    plt.savefig(f'result/{title}/ks_{rep}.png', dpi=300)\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 679.61it/s, D_loss=0.585, MI=-.00679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, D_loss: 0.5847071334719658, G_loss: 0.8912755131721497, MI = -0.006786556914448738\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.24282181753271426\n",
      "D_ks: 0.4885656762549702 p-value: 3.156350930584635e-143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 690.22it/s, D_loss=0.576, MI=-.0025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, D_loss: 0.5762233762070537, G_loss: 1.2410487413406373, MI = -0.0024979047011584044\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.16488574151005717\n",
      "D_ks: 0.4465040809828529 p-value: 2.516032116076891e-119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 661.95it/s, D_loss=0.537, MI=-.000321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, D_loss: 0.5368377990089357, G_loss: 1.1218065738677978, MI = -0.00032056262716650963\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.1899581661132802\n",
      "D_ks: 0.48623930246645125 p-value: 1.4925222858054488e-141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 691.39it/s, D_loss=0.567, MI=0.000811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, D_loss: 0.5667344781104475, G_loss: 1.118030834197998, MI = 0.0008105812594294548\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.15235226393489898\n",
      "D_ks: 0.4289992467072565 p-value: 3.831526977943217e-110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 674.41it/s, D_loss=0.552, MI=-.000119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, D_loss: 0.5517333457246423, G_loss: 1.1656736612319947, MI = -0.00011935108341276646\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.17210493302598737\n",
      "D_ks: 0.4304213779821074 p-value: 6.103111633334609e-111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 672.13it/s, D_loss=0.564, MI=0.000394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, D_loss: 0.5644709116313607, G_loss: 1.0549620270729065, MI = 0.0003936688881367445\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.13118365138711408\n",
      "D_ks: 0.4090811575857356 p-value: 3.9213757631707825e-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 680.73it/s, D_loss=0.544, MI=-.00198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, D_loss: 0.5443440470844507, G_loss: 1.407884454727173, MI = -0.001977987354621291\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.14658968039353665\n",
      "D_ks: 0.4143144065295725 p-value: 9.62467454297221e-103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 612.94it/s, D_loss=0.518, MI=0.000217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, D_loss: 0.5178511112462729, G_loss: 1.1712004661560058, MI = 0.00021690595895051956\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.25114494551902516\n",
      "D_ks: 0.4545073310139165 p-value: 4.620466991245964e-124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 623.09it/s, D_loss=0.555, MI=0.000595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, D_loss: 0.5551776473876089, G_loss: 1.0819551944732666, MI = 0.000594840501435101\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.12387653680013144\n",
      "D_ks: 0.41075034169980124 p-value: 6.256692464482115e-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 628.68it/s, D_loss=0.495, MI=0.000138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, D_loss: 0.49467958929017186, G_loss: 1.2047054290771484, MI = 0.00013838254380971193\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.20737446178273197\n",
      "D_ks: 0.4946818114749006 p-value: 1.3533350667090436e-146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 565.79it/s, D_loss=0.505, MI=0.000223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, D_loss: 0.5051255279686302, G_loss: 1.1609392881393432, MI = 0.00022312893997877836\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.1618653594675109\n",
      "D_ks: 0.47838166314612324 p-value: 6.766556031468143e-137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 685.35it/s, D_loss=0.524, MI=-.00095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, D_loss: 0.5235985331237316, G_loss: 1.4543727874755858, MI = -0.0009499747538939118\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.1806745389944768\n",
      "D_ks: 0.44836547123508946 p-value: 2.204429940787401e-120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 662.43it/s, D_loss=0.568, MI=0.000177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, D_loss: 0.5683586881496012, G_loss: 1.151388692855835, MI = 0.00017652742099016905\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.049859650092163414\n",
      "D_ks: 0.42971856361829025 p-value: 2.7344608007489526e-110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 681.04it/s, D_loss=0.549, MI=-.000242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, D_loss: 0.548645013011992, G_loss: 1.0807265639305115, MI = -0.0002417245414108038\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.049866751740960454\n",
      "D_ks: 0.4500865898359841 p-value: 5.9599444335923205e-121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 667.46it/s, D_loss=0.549, MI=-.00157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, D_loss: 0.548990972340107, G_loss: 1.2289535284042359, MI = -0.0015697048511356115\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.0481582769588566\n",
      "D_ks: 0.46765597819334 p-value: 1.5279678270242384e-130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 718.27it/s, D_loss=0.542, MI=-.000769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, D_loss: 0.5416255095042288, G_loss: 1.123613142967224, MI = -0.0007693211082369089\n",
      "진짜 corr =  0.40739779125851244 현재 corr =  -0.013355718888929492\n",
      "D_ks: 0.46406376195949306 p-value: 1.5920636870442628e-128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 650.93it/s, D_loss=0.535, MI=0.000601]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m     log_gen_codes\u001b[39m.\u001b[39mappend(code_input\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     66\u001b[0m \u001b[39m# train generator\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m generator_params, G_loss \u001b[39m=\u001b[39m spsa_step(generator_params)\n\u001b[1;32m     68\u001b[0m D_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     69\u001b[0m M_scheduler\u001b[39m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[35], line 27\u001b[0m, in \u001b[0;36mspsa_step\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     24\u001b[0m delta \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice([\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], size\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     25\u001b[0m z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, (MINIBATCH_SIZE, n_qubits))\n\u001b[0;32m---> 27\u001b[0m loss_plus \u001b[39m=\u001b[39m generator_cost_fn(params \u001b[39m+\u001b[39;49m c \u001b[39m*\u001b[39;49m delta, z) \u001b[39m# 실제론 shot=MINIBATCH_SIZE\u001b[39;00m\n\u001b[1;32m     28\u001b[0m loss_plus \u001b[39m=\u001b[39m loss_plus\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     29\u001b[0m loss_minus \u001b[39m=\u001b[39m generator_cost_fn(params \u001b[39m-\u001b[39m c \u001b[39m*\u001b[39m delta, z) \u001b[39m# 실제론 shot=MINIBATCH_SIZE\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[33], line 48\u001b[0m, in \u001b[0;36mgenerator_cost_fn\u001b[0;34m(params, generator_input, use_mine, _qmine)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerator_cost_fn\u001b[39m(params, generator_input, use_mine \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, _qmine \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     46\u001b[0m     code_input \u001b[39m=\u001b[39m generator_input[:, \u001b[39m-\u001b[39mcode_qubits:] \u001b[39m# 입력중에서 code만 뽑는다. (-1, code_qubits)\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     generator_output \u001b[39m=\u001b[39m generator_forward(params, generator_input) \u001b[39m# 출력을 뽑아낸다\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     generator_output \u001b[39m=\u001b[39m generator_output\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32) \u001b[39m# (-1, output_qubits)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     disc_output \u001b[39m=\u001b[39m discriminator(generator_output) \u001b[39m# 밑에 코드에서 정의됨\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[33], line 29\u001b[0m, in \u001b[0;36mgenerator_forward\u001b[0;34m(params, generator_input)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerator_forward\u001b[39m(params, generator_input):\n\u001b[0;32m---> 29\u001b[0m     generator_output \u001b[39m=\u001b[39m [generator_circuit(params, single_in) \u001b[39mfor\u001b[39;00m single_in \u001b[39min\u001b[39;00m generator_input]\n\u001b[1;32m     30\u001b[0m     values \u001b[39m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m     \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m generator_output:\n",
      "Cell \u001b[0;32mIn[33], line 29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerator_forward\u001b[39m(params, generator_input):\n\u001b[0;32m---> 29\u001b[0m     generator_output \u001b[39m=\u001b[39m [generator_circuit(params, single_in) \u001b[39mfor\u001b[39;00m single_in \u001b[39min\u001b[39;00m generator_input]\n\u001b[1;32m     30\u001b[0m     values \u001b[39m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m     \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m generator_output:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/pennylane/qnode.py:842\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         set_shots(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_device, override_shots)(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_gradient_fn)()\n\u001b[1;32m    841\u001b[0m \u001b[39m# construct the tape\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(args, kwargs)\n\u001b[1;32m    844\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    845\u001b[0m using_custom_cache \u001b[39m=\u001b[39m (\n\u001b[1;32m    846\u001b[0m     \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__getitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    847\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__setitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    848\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__delitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    849\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/pennylane/qnode.py:751\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m old_interface \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    749\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterface \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mget_interface(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues()))\n\u001b[0;32m--> 751\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape \u001b[39m=\u001b[39m make_qscript(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qfunc_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtape\u001b[39m.\u001b[39m_qfunc_output\n\u001b[1;32m    754\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtape\u001b[39m.\u001b[39mget_parameters(trainable_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/pennylane/tape/qscript.py:1371\u001b[0m, in \u001b[0;36mmake_qscript.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1370\u001b[0m     \u001b[39mwith\u001b[39;00m AnnotatedQueue() \u001b[39mas\u001b[39;00m q:\n\u001b[0;32m-> 1371\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1373\u001b[0m     qscript \u001b[39m=\u001b[39m QuantumScript\u001b[39m.\u001b[39mfrom_queue(q)\n\u001b[1;32m   1374\u001b[0m     qscript\u001b[39m.\u001b[39m_qfunc_output \u001b[39m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[33], line 24\u001b[0m, in \u001b[0;36mgenerator_circuit\u001b[0;34m(params, generator_input)\u001b[0m\n\u001b[1;32m     22\u001b[0m generator_init(generator_input)\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m params:\n\u001b[0;32m---> 24\u001b[0m     generator_layer(param)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m qml\u001b[39m.\u001b[39msample(wires\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(n_qubits))\n",
      "Cell \u001b[0;32mIn[33], line 11\u001b[0m, in \u001b[0;36mgenerator_layer\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerator_layer\u001b[39m(params):\n\u001b[1;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_qubits\u001b[39m-\u001b[39mcode_qubits):\n\u001b[0;32m---> 11\u001b[0m         qml\u001b[39m.\u001b[39mRZ(params[i][\u001b[39m0\u001b[39;49m], wires\u001b[39m=\u001b[39mi)\n\u001b[1;32m     12\u001b[0m         qml\u001b[39m.\u001b[39mRX(params[i][\u001b[39m1\u001b[39m], wires\u001b[39m=\u001b[39mi)\n\u001b[1;32m     13\u001b[0m         qml\u001b[39m.\u001b[39mRZ(params[i][\u001b[39m2\u001b[39m], wires\u001b[39m=\u001b[39mi)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/pennylane/numpy/tensor.py:190\u001b[0m, in \u001b[0;36mtensor.__getitem__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m item \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(item, tensor):\n\u001b[0;32m--> 190\u001b[0m     item \u001b[39m=\u001b[39m tensor(item, requires_grad\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequires_grad)\n\u001b[1;32m    192\u001b[0m \u001b[39mreturn\u001b[39;00m item\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/pennylane/numpy/tensor.py:111\u001b[0m, in \u001b[0;36mtensor.__new__\u001b[0;34m(cls, input_array, requires_grad, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, input_array, \u001b[39m*\u001b[39margs, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 111\u001b[0m     obj \u001b[39m=\u001b[39m asarray(input_array, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, onp\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    114\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mview(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m f_raw(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/pennylane/numpy/tensor.py:36\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(vals, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(vals, (onp\u001b[39m.\u001b[39mndarray, _np\u001b[39m.\u001b[39mndarray)):\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m _np\u001b[39m.\u001b[39masarray(vals, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 36\u001b[0m \u001b[39mreturn\u001b[39;00m _np\u001b[39m.\u001b[39;49marray(vals, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/autograd/numpy/numpy_wrapper.py:60\u001b[0m, in \u001b[0;36marray\u001b[0;34m(A, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m array_from_args(args, kwargs, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(array, A))\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_from_scalar_or_array(args, kwargs, A)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pennylane/lib/python3.10/site-packages/autograd/tracer.py:38\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m@wraps\u001b[39m(f_raw)\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf_wrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     boxed_args, trace, node_constructor \u001b[39m=\u001b[39m find_top_boxed_args(args)\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mif\u001b[39;00m boxed_args:\n\u001b[1;32m     39\u001b[0m         argvals \u001b[39m=\u001b[39m subvals(args, [(argnum, box\u001b[39m.\u001b[39m_value) \u001b[39mfor\u001b[39;00m argnum, box \u001b[39min\u001b[39;00m boxed_args])\n\u001b[1;32m     40\u001b[0m         \u001b[39mif\u001b[39;00m f_wrapped \u001b[39min\u001b[39;00m notrace_primitives[node_constructor]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ndtest\n",
    "import openpyxl\n",
    "epoch = 1500\n",
    "\n",
    "recorder_keywords = ['d_loss', 'g_loss', 'mi', 'corr', 'D_ks', 'p-value']\n",
    "for i in range(code_qubits):\n",
    "    recorder_keywords.append(f'code{i}-x')\n",
    "    recorder_keywords.append(f'code{i}-y')\n",
    "\n",
    "recorder = {k: [] for k in recorder_keywords}\n",
    "final_rep = 0\n",
    "\n",
    "c_target = np.corrcoef(target_distribution[:,0], target_distribution[:,1])[0,1]\n",
    "\n",
    "x_recorder = []\n",
    "\n",
    "for rep in range(1, epoch+1):\n",
    "    np.random.shuffle(target_distribution)\n",
    "    iter_num = int(BATCH_SIZE  // MINIBATCH_SIZE) # 매번 50% 추출해서 학습. 셔플하니까 자투리 생기는건 무시.\n",
    "    #iter_num = 16\n",
    "    generator_seeds = torch.rand((BATCH_SIZE, n_qubits)) * 2 - 1 # seed = (2048, n_qubits)\n",
    "    gen_outputs = generator_forward(generator_params, generator_seeds).detach() # 2048번 돌아간다\n",
    "\n",
    "    D_loss_sum = 0.0\n",
    "    mi_sum = 0.0\n",
    "    log_gen_outputs = []\n",
    "    log_gen_codes = []\n",
    "    \n",
    "    a_sum = 0\n",
    "    b_sum = 0\n",
    "    \n",
    "    pbar = tqdm(range(iter_num))\n",
    "    \n",
    "    for i in pbar:\n",
    "        x_indices = np.random.choice(len(target_distribution), size=MINIBATCH_SIZE)\n",
    "        batch = torch.FloatTensor(target_distribution[x_indices])\n",
    "\n",
    "        fake_input = gen_outputs[MINIBATCH_SIZE * i : MINIBATCH_SIZE * i + MINIBATCH_SIZE]\n",
    "        generator_seed = generator_seeds[MINIBATCH_SIZE * i : MINIBATCH_SIZE * i + MINIBATCH_SIZE]\n",
    "\n",
    "        # train discriminator\n",
    "        disc_loss = disc_cost_fn(batch, fake_input, smoothing=False)\n",
    "        D_opt.zero_grad()\n",
    "        disc_loss.requires_grad_(True)\n",
    "        disc_loss.backward()\n",
    "        D_opt.step()\n",
    "\n",
    "        # train mine\n",
    "        code_input = generator_seed[:, -code_qubits:] \n",
    "        pred_xy = mine(code_input, fake_input)\n",
    "        code_input_shuffle = code_input[torch.randperm(len(code_input))]\n",
    "        pred_x_y = mine(code_input_shuffle, fake_input)\n",
    "        mi = -torch.mean(pred_xy) + torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        M_opt.zero_grad()\n",
    "        mi.requires_grad_(True)\n",
    "        mi.backward()\n",
    "        M_opt.step()\n",
    "\n",
    "        D_loss_sum += disc_loss.item()\n",
    "        mi_sum -= mi.item() # (-1)곱해져 있어서 빼야함.\n",
    "\n",
    "        pbar.set_postfix({'D_loss': D_loss_sum/(i+1), 'MI': mi_sum/(i+1)})\n",
    "        log_gen_outputs.append(fake_input.numpy())\n",
    "        log_gen_codes.append(code_input.numpy())\n",
    "\n",
    "    # train generator\n",
    "    generator_params, G_loss = spsa_step(generator_params)\n",
    "    D_scheduler.step()\n",
    "    M_scheduler.step()\n",
    "\n",
    "    recorder['d_loss'].append(D_loss_sum/iter_num)\n",
    "    recorder['g_loss'].append(G_loss)\n",
    "    recorder['mi'].append(mi_sum/iter_num)\n",
    "    \n",
    "    gen_outputs = gen_outputs.numpy()\n",
    "    print(\"epoch: {}, D_loss: {}, G_loss: {}, MI = {}\".format(rep, D_loss_sum/iter_num, G_loss, mi_sum/iter_num))\n",
    "    \n",
    "    df = pd.DataFrame({'x': gen_outputs[:, 0], 'y': gen_outputs[:, 1]})\n",
    "    for i in range(code_qubits):\n",
    "        df[f'code{i}']=generator_seeds[:, i]\n",
    "    corr_mat = df.corr().to_numpy()\n",
    "    for i in range(code_qubits):\n",
    "        recorder[f'code{i}-x'].append(corr_mat[0, i+2])\n",
    "        recorder[f'code{i}-y'].append(corr_mat[1, i+2])\n",
    "    \n",
    "    rev_x, rev_y = reverse_probability_integral_transform(gen_outputs[:,0], gen_outputs[:,1],\n",
    "                                                      stock_returns[\"AAPL\"].mean(), stock_returns[\"AAPL\"].std(),\n",
    "                                                      stock_returns[\"MSFT\"].mean(), stock_returns[\"MSFT\"].std())\n",
    "    rev_corr = np.corrcoef(rev_x, rev_y)[0,1]\n",
    "    recorder['corr'].append(rev_corr)\n",
    "\n",
    "    our_output = np.column_stack([rev_x, rev_y])\n",
    "    p_value, D_ks = ndtest.ks2d2s(rev_x, rev_y, stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values, extra=True)\n",
    "\n",
    "    print(\"진짜 corr = \", c_target, \"현재 corr = \", rev_corr)\n",
    "    print(\"D_ks:\", D_ks, \"p-value:\", p_value)\n",
    "    recorder['D_ks'].append(D_ks)\n",
    "    recorder['p-value'].append(p_value)\n",
    "\n",
    "    if rep % 10 == 0:\n",
    "        visualize_output(gen_outputs, generator_seeds, (rev_x, rev_y), title, rep, recorder)\n",
    "        with open(f'result/{title}/discriminator_{rep}.pkl', 'wb') as file:\n",
    "            pickle.dump(discriminator, file)\n",
    "        with open(f'result/{title}/generator_{rep}.pkl', 'wb') as file:\n",
    "            pickle.dump(generator_params, file)\n",
    "\n",
    "    df = pd.DataFrame(recorder)\n",
    "    output_filename = f'result/{title}/recorder.xlsx'\n",
    "    df.to_excel(output_filename, index=False)\n",
    "\n",
    "    final_rep = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_outputs[:,0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 지표 엑셀파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "df = pd.DataFrame(recorder)\n",
    "output_filename = f'result/{title}/recorder.xlsx'\n",
    "df.to_excel(output_filesname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 결과 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for i in tqdm(range(5000)):\n",
    "    with torch.no_grad():\n",
    "        z = np.random.uniform(-1, 1, (1, n_qubits, 1))\n",
    "        code_input = z[:, -code_qubits:].reshape(code_qubits) # 입력 z중에서 code를 추출한다.\n",
    "        generator_output = generator_forward(generator_params, z, copula=output_copula)\n",
    "        generator_output = generator_output.cpu().numpy().reshape(2)\n",
    "        outputs.append(generator_output)\n",
    "        inputs.append(code_input)\n",
    "\n",
    "inputs = np.array(inputs).reshape(-1, code_qubits)\n",
    "\n",
    "for code_ind in range(code_qubits):\n",
    "    outputs = np.array(outputs)\n",
    "    plt.scatter(outputs[:, 0], outputs[:, 1], c=inputs[:, code_ind], cmap='RdYlBu', alpha=0.2)\n",
    "    plt.colorbar()  # 색상 막대 추가\n",
    "    plt.title(f'code{code_ind}-distribution (rep = {final_rep})')\n",
    "    plt.savefig(f'result/{title}/code_{code_ind}_{final_rep}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
