{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from functools import reduce\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 금융 데이터를 yfinance로부터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "def get_stocks_datas(ticker_names: list[str], start_date, end_date):\n",
    "    # WARN: returns는 prices보다 길이가 1 작다.\n",
    "    prices = {}\n",
    "    returns = {}\n",
    "    for name in ticker_names:\n",
    "        data = yf.Ticker(name)\n",
    "        data = data.history(start=start_date, end=end_date, interval=\"1d\")\n",
    "        prices[name] = data['Close']\n",
    "        returns[name] = data['Close'].pct_change()[1:]\n",
    "    return prices, returns\n",
    "\n",
    "start_date = datetime.datetime(2010, 1, 1)\n",
    "end_date = datetime.datetime(2017, 12, 31)\n",
    "stock_prices, stock_returns = get_stocks_datas([\"AAPL\", \"MSFT\"], start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산점도 그리기\n",
    "plt.scatter(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values, alpha=0.5)\n",
    "plt.title(f'AAPL/MSFT daily returns')\n",
    "plt.xlabel('AAPL')\n",
    "plt.ylabel('MSFT')\n",
    "plt.xlim(-0.15, 0.15)\n",
    "plt.ylim(-0.15, 0.15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copula 변환/역변환 준비\n",
    "\n",
    "역변환은 기존 분포를 normal distribution이라 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import random\n",
    "\n",
    "def probability_integral_transform(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    n = len(x)\n",
    "    x_sorted = sorted([(x, i) for i, x in enumerate(x)])\n",
    "    y_sorted = sorted([(y, i) for i, y in enumerate(y)])\n",
    "    xx = np.zeros(n)\n",
    "    yy = np.zeros(n)\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        xx[x_sorted[i][1]] = i / n\n",
    "        yy[y_sorted[i][1]] = i / n\n",
    "        \n",
    "    return xx, yy\n",
    "\n",
    "def reverse_probability_integral_transform(x, y, x_mean, x_std, y_mean, y_std):\n",
    "    assert(len(x) == len(y))\n",
    "    n = len(x)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for i in range(n):\n",
    "        # 정규분포에서 면적이 x[i] 가 되는 z값\n",
    "        xx.append(norm.ppf(x[i], loc=x_mean, scale=x_std))\n",
    "        yy.append(norm.ppf(y[i], loc=y_mean, scale=y_std))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_x, copula_y = probability_integral_transform(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values)\n",
    "plt.scatter(copula_x, copula_y, s=20)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Copula space plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_distribution = np.column_stack((copula_x, copula_y))\n",
    "plt.scatter(target_distribution[:,0], target_distribution[:,1], s=2.0)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting torch device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_qubits = 6\n",
    "code_qubits = 1\n",
    "n_qubits = noise_qubits + code_qubits\n",
    "\n",
    "n_layers = 1\n",
    "print(\"n_qubits = {} n_layers = {}\".format(n_qubits, n_layers))\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "MINIBATCH_SIZE = 16\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits, shots=1) # 제너레이터 돌려서 값 뽑아내는데 쓰임. 이중 몇개 골라서 판별자도 학습함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 0.2\n",
    "\n",
    "def generator_init(generator_input):\n",
    "    for i in range(noise_qubits):\n",
    "        qml.Hadamard(wires=i)\n",
    "    for i in range(noise_qubits//2):\n",
    "        qml.CNOT(wires=[i, i+noise_qubits//2])\n",
    "\n",
    "def generator_layer(params):\n",
    "    for i in range(n_qubits-code_qubits):\n",
    "        qml.RZ(params[i][0], wires=i)\n",
    "        qml.RX(params[i][1], wires=i)\n",
    "        qml.RZ(params[i][2], wires=i)\n",
    "    \n",
    "    for i in range(n_qubits-code_qubits):\n",
    "        qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
    "        qml.RX(params[i][3], wires=i)\n",
    "        qml.CNOT(wires=[i, (i+2)%n_qubits])\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def generator_circuit(params, generator_input):\n",
    "    generator_init(generator_input)\n",
    "    for param in params:\n",
    "        generator_layer(param)\n",
    "    return qml.sample(wires=range(n_qubits))\n",
    "\n",
    "\n",
    "def generator_forward(params, generator_input):\n",
    "    generator_output = [generator_circuit(params, single_in) for single_in in generator_input]\n",
    "    values = []\n",
    "    for output in generator_output:\n",
    "        gen_x = 0\n",
    "        gen_y = 0\n",
    "        for i in range(noise_qubits//2):\n",
    "            gen_x += (0.5**(i+1)) * output[i]\n",
    "        for i in range(noise_qubits//2, noise_qubits):\n",
    "            gen_y += (0.5**(i-noise_qubits//2+1)) * output[i]\n",
    "        gen_x += random.randint(0, (2**20)-1) / (2**23)\n",
    "        gen_y += random.randint(0, (2**20)-1) / (2**23)\n",
    "        values.append([gen_x, gen_y])\n",
    "    generator_output = torch.tensor(values) # (-1, 2) 차원\n",
    "    return generator_output\n",
    "\n",
    "\n",
    "def generator_cost_fn(params, generator_input, use_mine = False, _qmine = False):\n",
    "    code_input = generator_input[:, -code_qubits:] # 입력중에서 code만 뽑는다. (-1, code_qubits)\n",
    "\n",
    "    generator_output = generator_forward(params, generator_input) # 출력을 뽑아낸다\n",
    "    generator_output = generator_output.to(torch.float32) # (-1, output_qubits)\n",
    "    \n",
    "    disc_output = discriminator(generator_output) # 밑에 코드에서 정의됨\n",
    "    gan_loss = -torch.log(disc_output).mean()\n",
    "    \n",
    "    if use_mine:\n",
    "        pred_xy = mine(code_input, generator_output)\n",
    "        code_input_shuffle = code_input[torch.randperm(len(code_input))]\n",
    "        pred_x_y = mine(code_input_shuffle, generator_output)\n",
    "        mi = torch.mean(pred_xy) - torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        gan_loss -= coeff * mi\n",
    "\n",
    "    elif _qmine:\n",
    "        gan_loss += 0 # TODO: qmine loss 추가하기\n",
    "\n",
    "    return gan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LinearDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(len(x.shape) != 2):\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class LinearMine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMine, self).__init__()\n",
    "        H = 32\n",
    "        self.fc1 = nn.Linear(code_qubits, H)\n",
    "        self.fc2 = nn.Linear(2, H)\n",
    "        self.fc3 = nn.Linear(H, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h1 = F.relu(self.fc1(x)+self.fc2(y))\n",
    "        h2 = self.fc3(h1)\n",
    "        return h2\n",
    "\n",
    "disc_loss_fn = nn.BCELoss()\n",
    "def disc_cost_fn(real_input, fake_input, smoothing=False):\n",
    "\n",
    "    disc_real = discriminator(real_input)\n",
    "    disc_fake = discriminator(fake_input)\n",
    "\n",
    "    if smoothing:\n",
    "        real_label = real_label - 0.2*torch.rand(real_label.shape).to(device)\n",
    "    #print(\"disc debug하자 \",\"real = \", disc_real.mean().item(), disc_real.std().item(), \"fake = \", disc_fake.mean().item(), disc_fake.std().item())\n",
    "    #print(\"항별 값 = \", torch.log(disc_real).mean() , torch.log(1.0 - disc_fake).mean())\n",
    "    \n",
    "    #loss = -0.5 * (torch.log(disc_real).mean() + torch.log(1.0 - disc_fake).mean())\n",
    "\n",
    "    real_label = torch.ones((real_input.shape[0], 1)).to(device)\n",
    "    fake_label = torch.zeros((fake_input.shape[0], 1)).to(device)\n",
    "    \n",
    "    a = disc_loss_fn(disc_real, real_label)\n",
    "    b = disc_loss_fn(disc_fake, fake_label)\n",
    "    return (a+b)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom spsa optimizer\n",
    "\n",
    "구현 오류 제보 환영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPSA_opt():\n",
    "    def __init__(self, a=0.008, c=0.01, n_iter = 5, gamma=0.101):\n",
    "        self.epoch = 1\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "        self.n_iter = n_iter\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def step(self):\n",
    "        self.epoch += 1\n",
    "    \n",
    "    def get_params(self):\n",
    "        # (a, c) tuple return\n",
    "        return self.a/self.epoch, self.c/(self.epoch**self.gamma)\n",
    "\n",
    "def spsa_step(params):\n",
    "    # 한 iter당 n_iter * 2 * MINIBATCH_SIZE 만큼 순회함\n",
    "    # 기본값 = 5 * 2 * 16 = 160\n",
    "    # return값: 평균 loss\n",
    "    loss_sum = 0\n",
    "    spsa_opt = SPSA_opt()\n",
    "    for i in range(spsa_opt.n_iter):\n",
    "        a, c = spsa_opt.get_params()\n",
    "        delta = np.random.choice([-1, 1], size=params.shape)\n",
    "        z = np.random.uniform(-1, 1, (MINIBATCH_SIZE, n_qubits))\n",
    "\n",
    "        loss_plus = generator_cost_fn(params + c * delta, z) # 실제론 shot=MINIBATCH_SIZE\n",
    "        loss_plus = loss_plus.detach().numpy()\n",
    "        loss_minus = generator_cost_fn(params - c * delta, z) # 실제론 shot=MINIBATCH_SIZE\n",
    "        loss_minus = loss_minus.detach().numpy()\n",
    "\n",
    "        g = (loss_plus - loss_minus)/(2*c*delta)\n",
    "        # print('param = ', params[0], 'delta =', (a*g)[0], 'aft =', (params-a*g)[0])\n",
    "        params -= a*g\n",
    "        loss_sum = loss_sum + (loss_plus + loss_minus)/2\n",
    "        spsa_opt.step()\n",
    "    \n",
    "    return params, loss_sum / spsa_opt.n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_params = Variable(torch.tensor(np.random.uniform(0, 2*np.pi, (n_layers, n_qubits, 4))))\n",
    "print(\"parameter shape: \", generator_params.shape)\n",
    "\n",
    "discriminator = LinearDiscriminator()\n",
    "mine = LinearMine()\n",
    "\n",
    "D_lr = 0.0015\n",
    "M_lr = 1e-4\n",
    "use_mine = False\n",
    "use_qmine = False\n",
    "D_opt = torch.optim.Adam(discriminator.parameters(), lr=D_lr)\n",
    "M_opt = torch.optim.Adam(mine.parameters(), lr=M_lr)\n",
    "\n",
    "D_scheduler = torch.optim.lr_scheduler.StepLR(D_opt, step_size=30, gamma=0.85)\n",
    "M_scheduler = torch.optim.lr_scheduler.StepLR(M_opt, step_size=30, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "title = f'spsa18_{use_mine}'\n",
    "if not os.path.exists(f'result/{title}'):\n",
    "    os.makedirs(f'result/{title}')\n",
    "    \n",
    "with open(f'result/{title}/param.txt', 'w') as f:\n",
    "    f.write('D_lr = {}\\n'.format(D_lr))\n",
    "    f.write('M_lr = {}\\n'.format(M_lr))\n",
    "    f.write('D_scheduler: step={}, gamma={}\\n'.format(D_scheduler.step_size, D_scheduler.gamma))\n",
    "    f.write('M_scheduler: step={}, gamma={}\\n'.format(M_scheduler.step_size, M_scheduler.gamma))\n",
    "    f.write('coeff = {}\\n'.format(coeff))\n",
    "    f.write('use_mine = {}\\n'.format(use_mine))\n",
    "    f.write('use_qmine = {}\\n'.format(use_qmine))\n",
    "    f.write('n_qubits = {}\\n'.format(n_qubits))\n",
    "    f.write('noise_qubits = {}\\n'.format(noise_qubits))\n",
    "    f.write('code_qubits = {}\\n'.format(code_qubits))\n",
    "    f.write('n_layers = {}\\n'.format(n_layers))\n",
    "    f.write('param shape = {}\\n'.format(generator_params.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def visualize_output(gen_outputs, gen_codes, rev, title, rep, recorder):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plt.figure(figsize=(10 + 4 * code_qubits, 7))  # 전체 그림의 크기 지정\n",
    "    \n",
    "    plt.subplot(2, 2 + code_qubits, 1)\n",
    "    plt.title('Target distribution')\n",
    "    plt.scatter(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"], s=10,  alpha=0.2)\n",
    "    plt.xlim((-0.2, 0.2))\n",
    "    plt.ylim((-0.2, 0.2))\n",
    "    plt.grid()\n",
    "\n",
    "    # 역변환\n",
    "    rev_x, rev_y = rev\n",
    "    plt.subplot(2, 2 + code_qubits, 2)\n",
    "    plt.title('Epoch {0}'.format(rep))\n",
    "    plt.scatter(rev_x, rev_y, s=10,  alpha=0.2)\n",
    "    plt.xlim((-0.2, 0.2))\n",
    "    plt.ylim((-0.2, 0.2))\n",
    "    plt.grid()\n",
    "\n",
    "    for i in range(code_qubits):\n",
    "        plt.subplot(2, 2 + code_qubits, 3 + i)\n",
    "        plt.title('Epoch {0} code {1}'.format(rep, i))\n",
    "        plt.scatter(rev_x, rev_y, s=10, c=gen_codes[:, i], cmap='RdYlBu', alpha=0.2)\n",
    "        plt.xlim((-0.2, 0.2))\n",
    "        plt.ylim((-0.2, 0.2))\n",
    "        plt.colorbar()  # 색상 막대 추가\n",
    "        plt.grid()\n",
    "    \n",
    "    \n",
    "    plt.subplot(2, 2 + code_qubits, 3 + code_qubits)\n",
    "    plt.title('Target copula'.format(rep))\n",
    "    plt.scatter(copula_x, copula_y, s=10,  alpha=0.2)\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2, 2 + code_qubits, 4 + code_qubits)\n",
    "    plt.title('Epoch {0} copula'.format(rep))\n",
    "    plt.scatter(gen_outputs[:, 0], gen_outputs[:, 1], s=10,  alpha=0.2)\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "\n",
    "    for i in range(code_qubits):\n",
    "        plt.subplot(2, 2 + code_qubits, 5 + code_qubits + i)\n",
    "        plt.title('Epoch {0} code {1}'.format(rep, i))\n",
    "        plt.scatter(gen_outputs[:, 0], gen_outputs[:, 1], s=10, c=gen_codes[:, i], cmap='RdYlBu', alpha=0.2)\n",
    "        plt.xlim((0, 1))\n",
    "        plt.ylim((0, 1))\n",
    "        plt.colorbar()  # 색상 막대 추가\n",
    "        plt.grid()\n",
    "\n",
    "    plt.savefig(f'result/{title}/{rep}.png', dpi=300)\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Epoch {0} code-axis corr'.format(rep))\n",
    "    for i in range(code_qubits):\n",
    "        plt.plot(recorder[f'code{i}-x'], label=f'code{i}-x', marker='o')\n",
    "        plt.plot(recorder[f'code{i}-y'], label=f'code{i}-y', marker='o')\n",
    "        plt.plot(recorder['mi'], label='mi', marker='o')\n",
    "        plt.plot(recorder['d_loss'], label='d_loss', marker='o')\n",
    "        plt.plot(recorder['g_loss'], label='g_loss', marker='o')\n",
    "        plt.plot(recorder['corr'], label='corr', marker='o')\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('correlation')\n",
    "    plt.ylim(-1, 2)\n",
    "    plt.title(f'code - axis corr graph (rep={rep})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'result/{title}/corr_{rep}.png', dpi=300)\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Epoch {0} KS stastics'.format(rep))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recorder['D_ks'], label='D_ks', marker='o')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recorder['p-value'], label='p-value', marker='o')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'result/{title}/ks_{rep}.png', dpi=300)\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 649.88it/s, D_loss=0.622, MI=-.000423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 186, D_loss: 0.6221813505981117, G_loss: 0.9840275883674622, MI = -0.0004233821528032422\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  0.013639874724897515\n",
      "D_ks: 0.16245398701540753 p-value: 4.00647251661307e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 641.80it/s, D_loss=0.619, MI=-.000298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 187, D_loss: 0.6192053658887744, G_loss: 0.8444195866584778, MI = -0.00029751553665846586\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  0.03589162603746398\n",
      "D_ks: 0.14962374192345923 p-value: 9.617204352042939e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 557.97it/s, D_loss=0.622, MI=-.000429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 188, D_loss: 0.6222850913181901, G_loss: 0.8764204025268555, MI = -0.00042877858504652977\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  0.06117970252359923\n",
      "D_ks: 0.13603001133822062 p-value: 1.9518641020895133e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 622.32it/s, D_loss=0.606, MI=1.18e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 189, D_loss: 0.6058926307596266, G_loss: 0.9300581932067871, MI = 1.1773430742323399e-05\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  0.0388497975521819\n",
      "D_ks: 0.145948527584493 p-value: 4.256006049342265e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 630.11it/s, D_loss=0.606, MI=-.000474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 190, D_loss: 0.6057551614940166, G_loss: 0.9240992069244385, MI = -0.00047383958008140326\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  0.032136191692267085\n",
      "D_ks: 0.1519996233536282 p-value: 3.6064307555092674e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 507.17it/s, D_loss=0.617, MI=-5.71e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 191, D_loss: 0.6173526314087212, G_loss: 0.9783982634544373, MI = -5.7104392908513546e-05\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  -0.01490897623553443\n",
      "D_ks: 0.1404638574801193 p-value: 3.672713027203849e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 625.26it/s, D_loss=0.591, MI=0.000748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 192, D_loss: 0.5912508242763579, G_loss: 1.035288405418396, MI = 0.0007480846252292395\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  -0.064550562713056\n",
      "D_ks: 0.17666170943091447 p-value: 5.366371575376255e-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 595.76it/s, D_loss=0.597, MI=0.00012] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 193, D_loss: 0.5966376911383122, G_loss: 1.0493292331695556, MI = 0.00011982035357505083\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  -0.04052838190797227\n",
      "D_ks: 0.15998248788518887 p-value: 1.187495183411797e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 643.60it/s, D_loss=0.567, MI=0.000259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 194, D_loss: 0.5673275575973094, G_loss: 1.0913577556610108, MI = 0.00025871419347822666\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  -0.11083567211027923\n",
      "D_ks: 0.19794611238817095 p-value: 9.26224841223478e-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 647.61it/s, D_loss=0.557, MI=0.000785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195, D_loss: 0.5572102305013686, G_loss: 1.1084367513656617, MI = 0.0007849952671676874\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  -0.14538523211948567\n",
      "D_ks: 0.21204511213966198 p-value: 3.171002522473297e-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 540.23it/s, D_loss=0.526, MI=-.000157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 196, D_loss: 0.5256942922715098, G_loss: 1.0013401508331299, MI = -0.00015706208068877459\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  -0.1141649387502242\n",
      "D_ks: 0.2290961263667992 p-value: 1.102869334650085e-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 687.99it/s, D_loss=0.583, MI=0.000622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 197, D_loss: 0.583245521876961, G_loss: 1.0576045989990235, MI = 0.0006221863441169262\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  -0.06061677425632799\n",
      "D_ks: 0.21523641354995027 p-value: 5.43637473188386e-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 636.78it/s, D_loss=0.582, MI=0.000111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 198, D_loss: 0.5819804698694497, G_loss: 1.0062008023262023, MI = 0.00011076871305704117\n",
      "진짜 corr =  0.4073977912585125 현재 corr =  0.02001958502899486\n",
      "D_ks: 0.20564066771247513 p-value: 1.4008585015207205e-25\n"
     ]
    }
   ],
   "source": [
    "import ndtest\n",
    "import openpyxl\n",
    "epoch = 1500\n",
    "\n",
    "recorder_keywords = ['d_loss', 'g_loss', 'mi', 'corr', 'D_ks', 'p-value']\n",
    "for i in range(code_qubits):\n",
    "    recorder_keywords.append(f'code{i}-x')\n",
    "    recorder_keywords.append(f'code{i}-y')\n",
    "\n",
    "recorder = {k: [] for k in recorder_keywords}\n",
    "final_rep = 0\n",
    "\n",
    "c_target = np.corrcoef(target_distribution[:,0], target_distribution[:,1])[0,1]\n",
    "\n",
    "x_recorder = []\n",
    "\n",
    "for rep in range(1, epoch+1):\n",
    "    np.random.shuffle(target_distribution)\n",
    "    iter_num = int(BATCH_SIZE  // MINIBATCH_SIZE) # 매번 50% 추출해서 학습. 셔플하니까 자투리 생기는건 무시.\n",
    "    #iter_num = 16\n",
    "    generator_seeds = torch.rand((BATCH_SIZE, n_qubits)) * 2 - 1 # seed = (2048, n_qubits)\n",
    "    gen_outputs = generator_forward(generator_params, generator_seeds).detach() # 2048번 돌아간다\n",
    "\n",
    "    D_loss_sum = 0.0\n",
    "    mi_sum = 0.0\n",
    "    log_gen_outputs = []\n",
    "    log_gen_codes = []\n",
    "    \n",
    "    a_sum = 0\n",
    "    b_sum = 0\n",
    "    \n",
    "    pbar = tqdm(range(iter_num))\n",
    "    \n",
    "    for i in pbar:\n",
    "        x_indices = np.random.choice(len(target_distribution), size=MINIBATCH_SIZE)\n",
    "        batch = torch.FloatTensor(target_distribution[x_indices])\n",
    "\n",
    "        fake_input = gen_outputs[MINIBATCH_SIZE * i : MINIBATCH_SIZE * i + MINIBATCH_SIZE]\n",
    "        generator_seed = generator_seeds[MINIBATCH_SIZE * i : MINIBATCH_SIZE * i + MINIBATCH_SIZE]\n",
    "\n",
    "        # train discriminator\n",
    "        disc_loss = disc_cost_fn(batch, fake_input, smoothing=False)\n",
    "        D_opt.zero_grad()\n",
    "        disc_loss.requires_grad_(True)\n",
    "        disc_loss.backward()\n",
    "        D_opt.step()\n",
    "\n",
    "        # train mine\n",
    "        code_input = generator_seed[:, -code_qubits:] \n",
    "        pred_xy = mine(code_input, fake_input)\n",
    "        code_input_shuffle = code_input[torch.randperm(len(code_input))]\n",
    "        pred_x_y = mine(code_input_shuffle, fake_input)\n",
    "        mi = -torch.mean(pred_xy) + torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        M_opt.zero_grad()\n",
    "        mi.requires_grad_(True)\n",
    "        mi.backward()\n",
    "        M_opt.step()\n",
    "\n",
    "        D_loss_sum += disc_loss.item()\n",
    "        mi_sum -= mi.item() # (-1)곱해져 있어서 빼야함.\n",
    "\n",
    "        pbar.set_postfix({'D_loss': D_loss_sum/(i+1), 'MI': mi_sum/(i+1)})\n",
    "        log_gen_outputs.append(fake_input.numpy())\n",
    "        log_gen_codes.append(code_input.numpy())\n",
    "\n",
    "    # train generator\n",
    "    generator_params, G_loss = spsa_step(generator_params)\n",
    "    D_scheduler.step()\n",
    "    M_scheduler.step()\n",
    "\n",
    "    recorder['d_loss'].append(D_loss_sum/iter_num)\n",
    "    recorder['g_loss'].append(G_loss)\n",
    "    recorder['mi'].append(mi_sum/iter_num)\n",
    "    \n",
    "    gen_outputs = gen_outputs.numpy()\n",
    "    print(\"epoch: {}, D_loss: {}, G_loss: {}, MI = {}\".format(rep, D_loss_sum/iter_num, G_loss, mi_sum/iter_num))\n",
    "    \n",
    "    df = pd.DataFrame({'x': gen_outputs[:, 0], 'y': gen_outputs[:, 1]})\n",
    "    for i in range(code_qubits):\n",
    "        df[f'code{i}']=generator_seeds[:, i]\n",
    "    corr_mat = df.corr().to_numpy()\n",
    "    for i in range(code_qubits):\n",
    "        recorder[f'code{i}-x'].append(corr_mat[0, i+2])\n",
    "        recorder[f'code{i}-y'].append(corr_mat[1, i+2])\n",
    "    \n",
    "    rev_x, rev_y = reverse_probability_integral_transform(gen_outputs[:,0], gen_outputs[:,1],\n",
    "                                                      stock_returns[\"AAPL\"].mean(), stock_returns[\"AAPL\"].std(),\n",
    "                                                      stock_returns[\"MSFT\"].mean(), stock_returns[\"MSFT\"].std())\n",
    "    rev_corr = np.corrcoef(rev_x, rev_y)[0,1]\n",
    "    recorder['corr'].append(rev_corr)\n",
    "\n",
    "    our_output = np.column_stack([rev_x, rev_y])\n",
    "    p_value, D_ks = ndtest.ks2d2s(rev_x, rev_y, stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values, extra=True)\n",
    "\n",
    "    print(\"진짜 corr = \", c_target, \"현재 corr = \", rev_corr)\n",
    "    print(\"D_ks:\", D_ks, \"p-value:\", p_value)\n",
    "    recorder['D_ks'].append(D_ks)\n",
    "    recorder['p-value'].append(p_value)\n",
    "\n",
    "\n",
    "    visualize_output(gen_outputs, generator_seeds, (rev_x, rev_y), title, rep, recorder)\n",
    "\n",
    "    if rep % 10 == 0:\n",
    "        with open(f'result/{title}/discriminator_{rep}.pkl', 'wb') as file:\n",
    "            pickle.dump(discriminator, file)\n",
    "        with open(f'result/{title}/generator_{rep}.pkl', 'wb') as file:\n",
    "            pickle.dump(generator_params, file)\n",
    "\n",
    "    df = pd.DataFrame(recorder)\n",
    "    output_filename = f'result/{title}/recorder.xlsx'\n",
    "    df.to_excel(output_filename, index=False)\n",
    "\n",
    "    final_rep = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_outputs[:,0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 지표 엑셀파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "df = pd.DataFrame(recorder)\n",
    "output_filename = f'result/{title}/recorder.xlsx'\n",
    "df.to_excel(output_filesname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 결과 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for i in tqdm(range(5000)):\n",
    "    with torch.no_grad():\n",
    "        z = np.random.uniform(-1, 1, (1, n_qubits, 1))\n",
    "        code_input = z[:, -code_qubits:].reshape(code_qubits) # 입력 z중에서 code를 추출한다.\n",
    "        generator_output = generator_forward(generator_params, z, copula=output_copula)\n",
    "        generator_output = generator_output.cpu().numpy().reshape(2)\n",
    "        outputs.append(generator_output)\n",
    "        inputs.append(code_input)\n",
    "\n",
    "inputs = np.array(inputs).reshape(-1, code_qubits)\n",
    "\n",
    "for code_ind in range(code_qubits):\n",
    "    outputs = np.array(outputs)\n",
    "    plt.scatter(outputs[:, 0], outputs[:, 1], c=inputs[:, code_ind], cmap='RdYlBu', alpha=0.2)\n",
    "    plt.colorbar()  # 색상 막대 추가\n",
    "    plt.title(f'code{code_ind}-distribution (rep = {final_rep})')\n",
    "    plt.savefig(f'result/{title}/code_{code_ind}_{final_rep}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
