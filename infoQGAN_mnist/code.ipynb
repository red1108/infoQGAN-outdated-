{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "from functools import reduce\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "# 1. 데이터 불러오기\n",
    "train_data = datasets.MNIST(root='./data/02/', train=True, download=True)\n",
    "test_data = datasets.MNIST(root='./data/02/', train=False, download=True)\n",
    "x_train = train_data.data.numpy()\n",
    "y_train = train_data.targets.numpy()\n",
    "x_test = test_data.data.numpy()\n",
    "y_test = test_data.targets.numpy()\n",
    "print('====전처리 이전=====')\n",
    "print('number of training data : ', x_train.shape, y_train.shape)\n",
    "print('number of test data : ', x_test.shape, y_test.shape)\n",
    "\n",
    "#######\n",
    "train_size = 1000\n",
    "imgw = 16\n",
    "#######\n",
    "\n",
    "# 0만 고른다\n",
    "GENERATING_NUMBER = 1\n",
    "x_train_origin = x_train[y_train == GENERATING_NUMBER]\n",
    "x_train_origin = x_train_origin[:train_size]\n",
    "x_test_origin = x_test[y_test == GENERATING_NUMBER]\n",
    "x_train_origin, x_test_origin = x_train_origin/255.0, x_test_origin/255.0\n",
    "\n",
    "\n",
    "# 4x4로 resize\n",
    "x_train = np.array([cv2.resize(img, dsize=(imgw, imgw)) for img in x_train_origin])\n",
    "x_test = np.array([cv2.resize(img, dsize=(imgw, imgw)) for img in x_test_origin])\n",
    "\n",
    "# 최대값 1로 고정\n",
    "# add noise\n",
    "x_train = x_train + np.random.normal(0, 0.02, size=x_train.shape)\n",
    "x_train = x_train / np.max(x_train, axis=(1, 2), keepdims=True)\n",
    "x_test = x_test / np.max(x_test, axis=(1, 2), keepdims=True)\n",
    "\n",
    "print(\"train shape = \", x_train.shape)\n",
    "print(\"test shape = \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating a figure with two subplots\n",
    "fig, axs = plt.subplots(1,2, figsize=(4, 8))\n",
    "t = np.random.randint(0, train_size)\n",
    "axs[0].imshow(x_train_origin[t])\n",
    "axs[1].imshow(x_train[t])\n",
    "plt.title(f'origin-reshape img of {t}th')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_qubits = 8\n",
    "code_qubits = 1\n",
    "n_qubits = noise_qubits + code_qubits\n",
    "assert(imgw**2 <= 2**n_qubits) # 출력 큐빗은 noise qubit이하여야 한다.\n",
    "\n",
    "n_layers = 25\n",
    "BATCH_SIZE = 16\n",
    "print(\"n_qubits = {} n_layers = {}\".format(n_qubits, n_layers))\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "random_indices = np.random.choice(2**n_qubits, imgw**2, replace=False)\n",
    "mask = np.zeros(2**n_qubits, dtype=bool)\n",
    "mask[random_indices] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 0.1\n",
    "\n",
    "def generator_init(generator_input):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(generator_input[i]*np.pi/2, wires=i) # TODO: *a 해서 값 범위 맞추기\n",
    "\n",
    "def generator_layer(params):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RX(params[i][0], wires=i)\n",
    "        qml.RY(params[i][1], wires=i)\n",
    "        qml.RZ(params[i][2], wires=i)\n",
    "    \n",
    "    for i in range(n_qubits):\n",
    "        qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def generator_circuit(params, generator_input):\n",
    "    \"\"\"\n",
    "    quantum circuit nodeq1\n",
    "    generator_input (np.array(큐빗)) : 생성기 입력 seed (noise + code)\n",
    "    params (torch.Tensor(레이어,큐빗,3)): a parameter\n",
    "    마지막 측정은 모두 Z로\n",
    "    \"\"\"\n",
    "\n",
    "    generator_init(generator_input)\n",
    "\n",
    "    for param in params:\n",
    "        generator_layer(param)\n",
    "\n",
    "    return qml.probs(wires=range(n_qubits))\n",
    "\n",
    "def generator_forward(params, generator_input):\n",
    "    # 제너레이터 돌리고 결과 return하는 함수\n",
    "    generator_output = [generator_circuit(params, single_in) for single_in in generator_input] # (BATCH_SIZE, 2**n_qubits) 차원\n",
    "    generator_output = torch.stack(generator_output) # (BATCH_SIZE, 2**n_qubits) 차원\n",
    "\n",
    "    output = generator_output[:, mask]\n",
    "    output /= generator_output.sum(dim=1, keepdim=True) # (BATCH_SIZE, n_qubits) 차원\n",
    "    # 곱하기 2 해서 범위를 초과하게 만들음\n",
    "    #output = generator_output[:, mask] / generator_output[:, mask_inv]\n",
    "    \n",
    "    output = output / output.max(dim=1, keepdim=True)[0]\n",
    "\n",
    "    return output, generator_output[:, -code_qubits:] # noise, code 순서로 반환\n",
    "\n",
    "\n",
    "def generator_train_step(params, generator_input, use_mine = False, _qmine = False):\n",
    "    '''\n",
    "    params (torch.Tensor(레이어,큐빗,3)): a parameter\n",
    "    generator_input (torch.Tensor(BATCH_SIZE, n_qubits)): 생성기 입력 seed (noise + code). -1~1 사이의 값\n",
    "    '''\n",
    "    code_input = generator_input[:, -code_qubits:] # 입력중에서 code만 뽑는다. (BATCH_SIZE, code_qubits)\n",
    "\n",
    "    generator_output, code_output = generator_forward(params, generator_input) # 출력을 뽑아낸다\n",
    "    generator_output = generator_output.to(torch.float32) # (BATCH_SIZE, output_qubits)\n",
    "    \n",
    "    disc_output = discriminator(generator_output) # 밑에 코드에서 정의됨\n",
    "    gan_loss = torch.log(1-disc_output).mean()\n",
    "    # print(\"gan_loss = \", gan_loss, gan_loss.shape)\n",
    "    \n",
    "    t = (code_input - code_output).pow(2).mean()\n",
    "\n",
    "    if use_mine:\n",
    "        pred_xy = mine(code_input, generator_output)\n",
    "        code_input_shuffle = code_input[torch.randperm(BATCH_SIZE)]\n",
    "        pred_x_y = mine(code_input_shuffle, generator_output)\n",
    "        mi = torch.mean(pred_xy) - torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        gan_loss -= coeff * mi\n",
    "\n",
    "    elif _qmine:\n",
    "        gan_loss += 0 # TODO: qmine loss 추가하기\n",
    "\n",
    "    return generator_output, gan_loss+t*0, gan_loss, t # TODO: 이건 분석용으로 넣어놓음.지워야 함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LinearDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim=imgw**2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(len(x.shape) != 2):\n",
    "            x = x.view(x.shape[0], -1)\n",
    "\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class LinearMine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMine, self).__init__()\n",
    "        H = 50\n",
    "        self.fc1 = nn.Linear(code_qubits, H)\n",
    "        self.fc2 = nn.Linear(imgw**2, H)\n",
    "        self.fc3 = nn.Linear(H, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h1 = F.relu(self.fc1(x)+self.fc2(y))\n",
    "        h2 = self.fc3(h1)\n",
    "        return h2\n",
    "\n",
    "disc_loss_fn = nn.BCELoss()\n",
    "def disc_cost_fn(real_input, fake_input, smoothing=False):\n",
    "    batch_num = real_input.shape[0]\n",
    "    disc_real = discriminator(real_input)\n",
    "    disc_fake = discriminator(fake_input)\n",
    "\n",
    "    real_label = torch.ones((batch_num, 1))\n",
    "    fake_label = torch.zeros((batch_num, 1))\n",
    "    \n",
    "    if smoothing:\n",
    "        real_label = real_label - 0.2*torch.rand(real_label.shape).to(device)\n",
    "    \n",
    "    loss = 0.5 * (disc_loss_fn(disc_real, real_label) + disc_loss_fn(disc_fake, fake_label))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_lr = 1e-4\n",
    "D_lr = 2e-5\n",
    "M_lr = 1e-4\n",
    "use_mine = True\n",
    "use_qmine = False\n",
    "\n",
    "generator_params = Variable(torch.tensor(np.random.uniform(-np.pi, np.pi, (n_layers, n_qubits, 3))), requires_grad=True)\n",
    "print(\"parameter shape: \", generator_params.shape)\n",
    "\n",
    "discriminator = LinearDiscriminator()\n",
    "mine = LinearMine()\n",
    "\n",
    "G_opt = torch.optim.Adam([generator_params], lr=G_lr)\n",
    "D_opt = torch.optim.Adam(discriminator.parameters(), lr=D_lr)\n",
    "M_opt = torch.optim.Adam(mine.parameters(), lr=M_lr)\n",
    "\n",
    "G_scheduler = torch.optim.lr_scheduler.StepLR(G_opt, step_size=30, gamma=0.7)\n",
    "D_scheduler = torch.optim.lr_scheduler.StepLR(D_opt, step_size=30, gamma=0.8)\n",
    "M_scheduler = torch.optim.lr_scheduler.StepLR(M_opt, step_size=30, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "title = f'try11_{use_mine}'\n",
    "folder_paths = [f'result/{title}', f'result/{title}/savepoints', f'result/{title}/graphs', f'result/{title}/samples']\n",
    "for path in folder_paths:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "with open(f'result/{title}/param.txt', 'w') as f:\n",
    "    f.write('G_lr = {}\\n'.format(G_lr))\n",
    "    f.write('D_lr = {}\\n'.format(D_lr))\n",
    "    f.write('M_lr = {}\\n'.format(M_lr))\n",
    "    f.write('G_scheduler: step={}, gamma={}\\n'.format(G_scheduler.step_size, G_scheduler.gamma))\n",
    "    f.write('D_scheduler: step={}, gamma={}\\n'.format(D_scheduler.step_size, D_scheduler.gamma))\n",
    "    f.write('M_scheduler: step={}, gamma={}\\n'.format(M_scheduler.step_size, M_scheduler.gamma))\n",
    "    f.write('coeff = {}\\n'.format(coeff))\n",
    "    f.write('use_mine = {}\\n'.format(use_mine))\n",
    "    f.write('use_qmine = {}\\n'.format(use_qmine))\n",
    "    f.write('n_qubits = {}\\n'.format(n_qubits))\n",
    "    f.write('imgw = {}\\n'.format(imgw))\n",
    "    f.write('code_qubits = {}\\n'.format(code_qubits))\n",
    "    f.write('n_layers = {}\\n'.format(n_layers))\n",
    "    f.write('param shape = {}\\n'.format(generator_params.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def visualize_output(log_gen_outputs, log_gen_codes, title, rep, recorder):\n",
    "\n",
    "    # 이미지 리스트에서 랜덤하게 8개 이미지 선택\n",
    "    num_images = 16\n",
    "    image_list = log_gen_outputs\n",
    "    image_indices = np.random.choice(len(image_list), num_images, replace=False)\n",
    "    selected_images = [image_list[i] for i in image_indices]\n",
    "    selected_codes = [log_gen_codes[i][0] for i in image_indices]\n",
    "\n",
    "    # 선택된 이미지를 reshape\n",
    "    reshaped_images = [image.reshape(imgw, imgw) for image in selected_images]\n",
    "    sorted_indices = np.argsort(selected_codes)\n",
    "    sorted_selected_codes = [selected_codes[i] for i in sorted_indices]\n",
    "    sorted_reshaped_images = [reshaped_images[i] for i in sorted_indices]\n",
    "\n",
    "    # 이미지를 2x4 배치로 그리기 위한 그리드 설정\n",
    "    grid_rows = 4\n",
    "    grid_cols = 4\n",
    "    gs = GridSpec(grid_rows, grid_cols)\n",
    "\n",
    "    # 이미지를 그리드에 배치하고 시각화\n",
    "    plt.figure(figsize=(8, 11))\n",
    "    for i, image in enumerate(sorted_reshaped_images):\n",
    "        row = i // grid_cols\n",
    "        col = i % grid_cols\n",
    "        ax = plt.subplot(gs[row, col])\n",
    "        ax.imshow(image)  # 이미지를 회색조로 표시\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{sorted_selected_codes[i]:.3f}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95, bottom=0.05)  # 위아래 간격 조절\n",
    "    plt.suptitle(f\"Epoch {rep}, random imgs\", fontsize=16)\n",
    "    plt.savefig(f'result/{title}/samples/{rep}.png')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(recorder['g_loss'], label='g_loss', marker='o')\n",
    "    plt.plot(recorder['d_loss'], label='d_loss', marker='o')\n",
    "    plt.plot(recorder['mi'], label='mi', marker='o')\n",
    "    plt.legend()\n",
    "    plt.title(f'Epoch {rep}, loss graph')\n",
    "    plt.savefig(f'result/{title}/graphs/{rep}.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 300\n",
    "\n",
    "recorder_keywords = ['d_loss', 'g_loss', 'a_loss', 'b_loss', 'mi']\n",
    "recorder = {k: [] for k in recorder_keywords}\n",
    "final_rep = 0\n",
    "\n",
    "for rep in range(1, epoch+1):\n",
    "    np.random.shuffle(x_train)\n",
    "    iter_num = int(len(x_train) * 0.5 //BATCH_SIZE) # 매번 50% 추출해서 학습. 셔플하니까 자투리 생기는건 무시.\n",
    "    \n",
    "    G_loss_sum = 0.0\n",
    "    D_loss_sum = 0.0\n",
    "    a_loss_sum = 0.0\n",
    "    b_loss_sum = 0.0\n",
    "    mi_sum = 0.0\n",
    "    log_gen_outputs = []\n",
    "    log_gen_codes = []\n",
    "    pbar = tqdm(range(iter_num))\n",
    "    \n",
    "    for i in pbar:\n",
    "        batch = torch.FloatTensor(x_train[BATCH_SIZE * i : BATCH_SIZE * i + BATCH_SIZE])\n",
    "        \n",
    "        # train generator\n",
    "        generator_seed = torch.rand((BATCH_SIZE, n_qubits)) * 2 - 1\n",
    "        generator_output, generator_loss, a, b = generator_train_step(generator_params, generator_seed, use_mine=use_mine, _qmine=use_qmine)\n",
    "        G_opt.zero_grad()\n",
    "        generator_loss.requires_grad_(True)\n",
    "        generator_loss.backward()\n",
    "        G_opt.step()\n",
    "        a_loss_sum += a.detach().numpy()\n",
    "        b_loss_sum += b.detach().numpy()\n",
    "\n",
    "        # train discriminator\n",
    "        fake_input = generator_output.detach().to(torch.float32)\n",
    "        disc_loss = disc_cost_fn(batch.reshape(-1, imgw**2), fake_input, smoothing=False)\n",
    "        D_opt.zero_grad()\n",
    "        disc_loss.requires_grad_(True)\n",
    "        disc_loss.backward()\n",
    "        D_opt.step()\n",
    "\n",
    "        # train mine\n",
    "        code_input = generator_seed[:, -code_qubits:] \n",
    "        pred_xy = mine(code_input, fake_input)\n",
    "        code_input_shuffle = code_input[torch.randperm(BATCH_SIZE)]\n",
    "        pred_x_y = mine(code_input_shuffle, fake_input)\n",
    "        mi = -torch.mean(pred_xy) + torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        M_opt.zero_grad()\n",
    "        mi.requires_grad_(True)\n",
    "        mi.backward()\n",
    "        M_opt.step()\n",
    "\n",
    "\n",
    "        D_loss_sum += disc_loss.item()\n",
    "        G_loss_sum += generator_loss.item()\n",
    "        mi_sum -= mi.item() # (-1)곱해져 있어서 빼야함.\n",
    "        a_loss_sum += a.item()\n",
    "        b_loss_sum += b.item()\n",
    "\n",
    "        pbar.set_postfix({'G_loss': G_loss_sum/(i+1), 'D_loss': D_loss_sum/(i+1), 'MI': mi_sum/(i+1)})\n",
    "        log_gen_outputs.append(fake_input.numpy())\n",
    "        log_gen_codes.append(code_input.numpy())\n",
    "\n",
    "    G_scheduler.step()\n",
    "    D_scheduler.step()\n",
    "    M_scheduler.step()\n",
    "\n",
    "    recorder['d_loss'].append(D_loss_sum/iter_num)\n",
    "    recorder['g_loss'].append(G_loss_sum/iter_num)\n",
    "    recorder['a_loss'].append(a_loss_sum/iter_num)\n",
    "    recorder['b_loss'].append(b_loss_sum/iter_num)\n",
    "    recorder['mi'].append(mi_sum/iter_num)\n",
    "    \n",
    "    log_gen_outputs = np.concatenate(log_gen_outputs, axis=0)\n",
    "    log_gen_codes = np.concatenate(log_gen_codes, axis=0)\n",
    "    print(\"epoch: {}, D_loss: {}, G_loss: {}, MI = {}\".format(rep, D_loss_sum/iter_num, G_loss_sum/iter_num, mi_sum/iter_num))\n",
    "    print(\"a_loss: {}, b_loss: {}\".format(a_loss_sum, b_loss_sum))\n",
    "\n",
    "    visualize_output(log_gen_outputs, log_gen_codes, title, rep, recorder)\n",
    "\n",
    "    with open(f'result/{title}/savepoints/discriminator_{rep}.pkl', 'wb') as file:\n",
    "        pickle.dump(discriminator, file)\n",
    "    with open(f'result/{title}/savepoints/generator_{rep}.pkl', 'wb') as file:\n",
    "        pickle.dump(generator_params, file)\n",
    "\n",
    "    final_rep = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "df = pd.DataFrame(recorder)\n",
    "output_filename = f'result/{title}/recorder.xlsx'\n",
    "df.to_excel(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
