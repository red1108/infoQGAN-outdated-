{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from functools import reduce\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 금융 데이터를 yfinance로부터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "def get_stocks_datas(ticker_names: list[str], start_date, end_date):\n",
    "    # WARN: returns는 prices보다 길이가 1 작다.\n",
    "    prices = {}\n",
    "    returns = {}\n",
    "    for name in ticker_names:\n",
    "        data = yf.Ticker(name)\n",
    "        data = data.history(start=start_date, end=end_date, interval=\"1d\")\n",
    "        prices[name] = data['Close']\n",
    "        returns[name] = data['Close'].pct_change()[1:]\n",
    "    return prices, returns\n",
    "\n",
    "start_date = datetime.datetime(2010, 1, 1)\n",
    "end_date = datetime.datetime(2017, 12, 31)\n",
    "stock_prices, stock_returns = get_stocks_datas([\"AAPL\", \"MSFT\"], start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산점도 그리기\n",
    "plt.scatter(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values, alpha=0.5)\n",
    "plt.title(f'AAPL/MSFT daily returns')\n",
    "plt.xlabel('AAPL')\n",
    "plt.ylabel('MSFT')\n",
    "plt.xlim(-0.15, 0.15)\n",
    "plt.ylim(-0.15, 0.15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copula 변환/역변환 준비\n",
    "\n",
    "역변환은 기존 분포를 normal distribution이라 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import random\n",
    "\n",
    "def probability_integral_transform(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    n = len(x)\n",
    "    x_sorted = sorted([(x, i) for i, x in enumerate(x)])\n",
    "    y_sorted = sorted([(y, i) for i, y in enumerate(y)])\n",
    "    xx = np.zeros(n)\n",
    "    yy = np.zeros(n)\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        xx[x_sorted[i][1]] = i / n\n",
    "        yy[y_sorted[i][1]] = i / n\n",
    "        \n",
    "    return xx, yy\n",
    "\n",
    "def reverse_probability_integral_transform(x, y, x_mean, x_std, y_mean, y_std):\n",
    "    assert(len(x) == len(y))\n",
    "    n = len(x)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for i in range(n):\n",
    "        # 정규분포에서 면적이 x[i] 가 되는 z값\n",
    "        xx.append(norm.ppf(x[i], loc=x_mean, scale=x_std))\n",
    "        yy.append(norm.ppf(y[i], loc=y_mean, scale=y_std))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copula_x, copula_y = probability_integral_transform(stock_returns[\"AAPL\"].values, stock_returns[\"MSFT\"].values)\n",
    "plt.scatter(copula_x, copula_y, s=20)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Copula space plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_x, rev_y = reverse_probability_integral_transform(copula_x, copula_y,\n",
    "                                                      stock_returns[\"AAPL\"].mean(), stock_returns[\"AAPL\"].std(),\n",
    "                                                      stock_returns[\"MSFT\"].mean(), stock_returns[\"MSFT\"].std())\n",
    "plt.scatter(rev_x, rev_y, alpha=0.5)\n",
    "print(max(rev_x),max(rev_y))\n",
    "plt.title(f'restored AAPL/MSFT daily returns')\n",
    "plt.xlabel('AAPL')\n",
    "plt.ylabel('MSFT')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stock_prices['AAPL'].values))\n",
    "print(len(stock_prices['MSFT'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.column_stack((stock_returns['AAPL'].values, stock_returns['MSFT'].values))\n",
    "plt.scatter(x[:,0], x[:,1], s=2.0)\n",
    "plt.title('Target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting torch device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_qubits = 6\n",
    "code_qubits = 1\n",
    "n_qubits = noise_qubits + code_qubits\n",
    "\n",
    "n_layers = 1\n",
    "BATCH_SIZE = 16\n",
    "print(\"n_qubits = {} n_layers = {}\".format(n_qubits, n_layers))\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 0\n",
    "\n",
    "def generator_init(generator_input):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(generator_input[i]*np.pi/2, wires=i) # TODO: *a 해서 값 범위 맞추기\n",
    "    for i in range(noise_qubits//2):\n",
    "        qml.Hadamard(wires=i)\n",
    "    for i in range(noise_qubits//2):\n",
    "        qml.CNOT(wires=[i, i+noise_qubits//2])\n",
    "\n",
    "def generator_layer(params):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RZ(params[i][0], wires=i)\n",
    "        qml.RX(params[i][1], wires=i)\n",
    "        qml.RZ(params[i][2], wires=i)\n",
    "    \n",
    "    for i in range(n_qubits):\n",
    "        qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
    "        qml.RX(params[i][3], wires=i)\n",
    "        qml.CNOT(wires=[i, (i+2)%n_qubits])\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def generator_circuit(params, generator_input):\n",
    "    \"\"\"\n",
    "    quantum circuit nodeq1\n",
    "    generator_input (np.array(큐빗)) : 생성기 입력 seed (noise + code)\n",
    "    params (torch.Tensor(레이어,큐빗,3)): a parameter\n",
    "    마지막 측정은 모두 Z로\n",
    "    \"\"\"\n",
    "\n",
    "    generator_init(generator_input)\n",
    "\n",
    "    for param in params:\n",
    "        generator_layer(param)\n",
    "\n",
    "    return [qml.probs(wires=i) for i in range(n_qubits)]\n",
    "\n",
    "def generator_forward(params, generator_input, copula=True):\n",
    "    # 제너레이터 돌리고 결과 return하는 함수\n",
    "    if copula:\n",
    "        # copula space의 출력으로 변환 [0~1]범위\n",
    "        generator_output = [generator_circuit(params, single_in)[::2] for single_in in generator_input]\n",
    "        values = []\n",
    "        for output in generator_output:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            for i in range(noise_qubits//2):\n",
    "                x += (0.5**(i+1)) * output[i]\n",
    "            for i in range(noise_qubits//2, noise_qubits):\n",
    "                y += (0.5**(i-noise_qubits//2+1)) * output[i]\n",
    "            x += random.randint(0, (2**20)-1) / (2**24)\n",
    "            y += random.randint(0, (2**20)-1) / (2**24)\n",
    "            values.append([x, y])\n",
    "        generator_output = torch.tensor(values) # (batch_size, 2) 차원\n",
    "        return generator_output\n",
    "    else:\n",
    "        # daily return 공간. 중심 0\n",
    "        generator_output = [generator_circuit(params, single_in)[::2] for single_in in generator_input]\n",
    "        generator_output = torch.stack(generator_output) # (BATCH_SIZE, n_qubits) 차원\n",
    "        generator_output = (2 / np.pi * torch.arcsin(torch.sqrt(generator_output)))-0.5 # (BATCH_SIZE, n_qubits) 차원\n",
    "        return generator_output[:, :2] # (BATCH_SIZE, 2) 차원\n",
    "\n",
    "def generator_train_step(params, generator_input, use_mine = False, _qmine = False):\n",
    "    '''\n",
    "    params (torch.Tensor(레이어,큐빗,3)): a parameter\n",
    "    generator_input (torch.Tensor(BATCH_SIZE, n_qubits)): 생성기 입력 seed (noise + code). -1~1 사이의 값\n",
    "    '''\n",
    "    code_input = generator_input[:, -code_qubits:] # 입력중에서 code만 뽑는다. (BATCH_SIZE, code_qubits)\n",
    "\n",
    "    generator_output = generator_forward(params, generator_input, copula=output_copula) # 출력을 뽑아낸다\n",
    "    generator_output = generator_output.to(torch.float32) # (BATCH_SIZE, output_qubits)\n",
    "    \n",
    "    disc_output = discriminator(generator_output) # 밑에 코드에서 정의됨\n",
    "    gan_loss = torch.log(1-disc_output).mean()\n",
    "    \n",
    "    if use_mine:\n",
    "        pred_xy = mine(code_input, generator_output)\n",
    "        code_input_shuffle = code_input[torch.randperm(BATCH_SIZE)]\n",
    "        pred_x_y = mine(code_input_shuffle, generator_output)\n",
    "        mi = torch.mean(pred_xy) - torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        gan_loss -= coeff * mi\n",
    "\n",
    "    elif _qmine:\n",
    "        gan_loss += 0 # TODO: qmine loss 추가하기\n",
    "\n",
    "    return generator_output, gan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LinearDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if(len(x.shape) != 2):\n",
    "            x = x.view(x.shape[0], -1)\n",
    "\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class LinearMine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearMine, self).__init__()\n",
    "        H = 30\n",
    "        self.fc1 = nn.Linear(code_qubits, H)\n",
    "        self.fc2 = nn.Linear(2, H)\n",
    "        self.fc3 = nn.Linear(H, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h1 = F.relu(self.fc1(x)+self.fc2(y))\n",
    "        h2 = self.fc3(h1)\n",
    "        return h2\n",
    "\n",
    "disc_loss_fn = nn.BCELoss()\n",
    "def disc_cost_fn(real_input, fake_input, smoothing=False):\n",
    "    batch_num = real_input.shape[0]\n",
    "\n",
    "    disc_real = discriminator(real_input)\n",
    "    disc_fake = discriminator(fake_input)\n",
    "\n",
    "    real_label = torch.ones((batch_num, 1)).to(device)\n",
    "    fake_label = torch.zeros((batch_num, 1)).to(device)\n",
    "    \n",
    "    if smoothing:\n",
    "        real_label = real_label - 0.2*torch.rand(real_label.shape).to(device)\n",
    "    \n",
    "    loss = 0.5 * (disc_loss_fn(disc_real, real_label) + disc_loss_fn(disc_fake, fake_label))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_params = Variable(torch.tensor(np.random.normal(0, np.pi, (n_layers, n_qubits, 4))), requires_grad=True)\n",
    "print(\"parameter shape: \", generator_params.shape)\n",
    "\n",
    "discriminator = LinearDiscriminator()\n",
    "mine = LinearMine()\n",
    "\n",
    "G_lr = 1e-3\n",
    "D_lr = 1.5e-4\n",
    "M_lr = 1e-3\n",
    "output_copula = False # true면 [0~1]범위 출력. false면 대략 -0.1~0.1범위 daily returns\n",
    "use_mine = True\n",
    "use_qmine = False\n",
    "G_opt = torch.optim.Adam([generator_params], lr=G_lr)\n",
    "D_opt = torch.optim.Adam(discriminator.parameters(), lr=D_lr)\n",
    "M_opt = torch.optim.Adam(mine.parameters(), lr=M_lr)\n",
    "\n",
    "G_scheduler = torch.optim.lr_scheduler.StepLR(G_opt, step_size=30, gamma=0.7)\n",
    "D_scheduler = torch.optim.lr_scheduler.StepLR(D_opt, step_size=30, gamma=0.85)\n",
    "M_scheduler = torch.optim.lr_scheduler.StepLR(M_opt, step_size=30, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "title = f'try5_returns_{use_mine}'\n",
    "if not os.path.exists(f'result/{title}'):\n",
    "    os.makedirs(f'result/{title}')\n",
    "    \n",
    "with open(f'result/{title}/param.txt', 'w') as f:\n",
    "    f.write('G_lr = {}\\n'.format(G_lr))\n",
    "    f.write('D_lr = {}\\n'.format(D_lr))\n",
    "    f.write('M_lr = {}\\n'.format(M_lr))\n",
    "    f.write('G_scheduler: step={}, gamma={}\\n'.format(G_scheduler.step_size, G_scheduler.gamma))\n",
    "    f.write('D_scheduler: step={}, gamma={}\\n'.format(D_scheduler.step_size, D_scheduler.gamma))\n",
    "    f.write('M_scheduler: step={}, gamma={}\\n'.format(M_scheduler.step_size, M_scheduler.gamma))\n",
    "    f.write('coeff = {}\\n'.format(coeff))\n",
    "    f.write('output_copula = {}\\n'.format(output_copula))\n",
    "    f.write('use_mine = {}\\n'.format(use_mine))\n",
    "    f.write('use_qmine = {}\\n'.format(use_qmine))\n",
    "    f.write('n_qubits = {}\\n'.format(n_qubits))\n",
    "    f.write('noise_qubits = {}\\n'.format(noise_qubits))\n",
    "    f.write('code_qubits = {}\\n'.format(code_qubits))\n",
    "    f.write('n_layers = {}\\n'.format(n_layers))\n",
    "    f.write('param shape = {}\\n'.format(generator_params.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_output(log_gen_outputs, log_gen_codes, title, rep, recorder):\n",
    "    plt.figure(figsize=(10 + 4 * code_qubits, 7))  # 전체 그림의 크기 지정\n",
    "    \n",
    "    plt.subplot(2, 2 + code_qubits, 1)\n",
    "    plt.title('Target distribution')\n",
    "    plt.scatter(x[:,0], x[:,1], s=10,  alpha=0.2)\n",
    "    plt.xlim((-0.2, 0.2))\n",
    "    plt.ylim((-0.2, 0.2))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2, 2 + code_qubits, 2)\n",
    "    plt.title('Epoch {0}'.format(rep))\n",
    "    plt.scatter(log_gen_outputs[:,0], log_gen_outputs[:,1], s=10,  alpha=0.2)\n",
    "    plt.xlim((-0.2, 0.2))\n",
    "    plt.ylim((-0.2, 0.2))\n",
    "    plt.grid()\n",
    "\n",
    "    for i in range(code_qubits):\n",
    "        plt.subplot(2, 2 + code_qubits, 3 + i)\n",
    "        plt.title('Epoch {0} code {1}'.format(rep, i))\n",
    "        plt.scatter(log_gen_outputs[:,0], log_gen_outputs[:,1], s=10, c=log_gen_codes[:, i], cmap='RdYlBu', alpha=0.2)\n",
    "        plt.xlim((-0.2, 0.2))\n",
    "        plt.ylim((-0.2, 0.2))\n",
    "        plt.colorbar()  # 색상 막대 추가\n",
    "        plt.grid()\n",
    "    \n",
    "    gen_copula_x, gen_copula_y = probability_integral_transform(log_gen_outputs[:,0], log_gen_outputs[:,1])\n",
    "    \n",
    "    plt.subplot(2, 2 + code_qubits, 3 + code_qubits)\n",
    "    plt.title('Target copula'.format(rep))\n",
    "    plt.scatter(copula_x, copula_y, s=10,  alpha=0.2)\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2, 2 + code_qubits, 4 + code_qubits)\n",
    "    plt.title('Epoch {0} copula'.format(rep))\n",
    "    plt.scatter(gen_copula_x, gen_copula_y, s=10,  alpha=0.2)\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "\n",
    "    for i in range(code_qubits):\n",
    "        plt.subplot(2, 2 + code_qubits, 5 + code_qubits + i)\n",
    "        plt.title('Epoch {0} code {1}'.format(rep, i))\n",
    "        plt.scatter(gen_copula_x, gen_copula_y, s=10, c=log_gen_codes[:, i], cmap='RdYlBu', alpha=0.2)\n",
    "        plt.xlim((0, 1))\n",
    "        plt.ylim((0, 1))\n",
    "        plt.colorbar()  # 색상 막대 추가\n",
    "        plt.grid()\n",
    "\n",
    "    plt.savefig(f'result/{title}/{rep}.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Epoch {0} code-axis corr'.format(rep))\n",
    "    for i in range(code_qubits):\n",
    "        plt.plot(recorder[f'code{i}-x'], label=f'code{i}-x', marker='o')\n",
    "        plt.plot(recorder[f'code{i}-y'], label=f'code{i}-y', marker='o')\n",
    "        plt.plot(recorder[f'mi'], label='mi', marker='o')\n",
    "        plt.plot(recorder[f'd_loss'], label='d_loss', marker='o')\n",
    "        plt.plot(recorder[f'g_loss'], label='g_loss', marker='o')\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('correlation')\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.title(f'code - axis corr graph (rep={rep})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'result/{title}/corr_{rep}.png', dpi=300)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 300\n",
    "\n",
    "recorder_keywords = ['d_loss', 'g_loss', 'mi', 'corr']\n",
    "for i in range(code_qubits):\n",
    "    recorder_keywords.append(f'code{i}-x')\n",
    "    recorder_keywords.append(f'code{i}-y')\n",
    "\n",
    "recorder = {k: [] for k in recorder_keywords}\n",
    "final_rep = 0\n",
    "\n",
    "c_target = np.corrcoef(x[:,0], x[:,1])[0,1]\n",
    "\n",
    "for rep in range(1, epoch+1):\n",
    "    np.random.shuffle(x)\n",
    "    iter_num = int(len(x) //BATCH_SIZE) # 매번 50% 추출해서 학습. 셔플하니까 자투리 생기는건 무시.\n",
    "    \n",
    "    G_loss_sum = 0.0\n",
    "    D_loss_sum = 0.0\n",
    "    a_loss_sum = 0.0\n",
    "    b_loss_sum = 0.0\n",
    "    mi_sum = 0.0\n",
    "    pbar = tqdm(range(iter_num))\n",
    "    log_gen_outputs = []\n",
    "    log_gen_codes = []\n",
    "\n",
    "    coeff = (1 + math.tanh((rep-100)/50))/10 # epoch100부터 mine을 고려하기 시작함\n",
    "    \n",
    "    for i in pbar:\n",
    "        batch = torch.FloatTensor(x[BATCH_SIZE * i : BATCH_SIZE * i + BATCH_SIZE])\n",
    "        \n",
    "        # train generator\n",
    "        generator_seed = torch.rand((BATCH_SIZE, n_qubits)) * 2 - 1\n",
    "        generator_output, generator_loss = generator_train_step(generator_params, generator_seed, use_mine=use_mine, _qmine=use_qmine)\n",
    "        G_opt.zero_grad()\n",
    "        generator_loss.requires_grad_(True)\n",
    "        generator_loss.backward()\n",
    "        G_opt.step()\n",
    "\n",
    "        # train discriminator\n",
    "        fake_input = generator_output.detach().to(torch.float32)\n",
    "        disc_loss = disc_cost_fn(batch, fake_input, smoothing=False)\n",
    "        D_opt.zero_grad()\n",
    "        disc_loss.requires_grad_(True)\n",
    "        disc_loss.backward()\n",
    "        D_opt.step()\n",
    "\n",
    "        # train mine\n",
    "        code_input = generator_seed[:, -code_qubits:] \n",
    "        pred_xy = mine(code_input, fake_input)\n",
    "        code_input_shuffle = code_input[torch.randperm(BATCH_SIZE)]\n",
    "        pred_x_y = mine(code_input_shuffle, fake_input)\n",
    "        mi = -torch.mean(pred_xy) + torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "        M_opt.zero_grad()\n",
    "        mi.requires_grad_(True)\n",
    "        mi.backward()\n",
    "        M_opt.step()\n",
    "\n",
    "\n",
    "        D_loss_sum += disc_loss.item()\n",
    "        G_loss_sum += generator_loss.item()\n",
    "        mi_sum -= mi.item() # (-1)곱해져 있어서 빼야함.\n",
    "\n",
    "        pbar.set_postfix({'G_loss': G_loss_sum/(i+1), 'D_loss': D_loss_sum/(i+1), 'MI': mi_sum/(i+1)})\n",
    "        log_gen_outputs.append(fake_input.numpy())\n",
    "        log_gen_codes.append(code_input.numpy())\n",
    "\n",
    "    G_scheduler.step()\n",
    "    D_scheduler.step()\n",
    "    M_scheduler.step()\n",
    "\n",
    "    recorder['d_loss'].append(D_loss_sum/iter_num)\n",
    "    recorder['g_loss'].append(G_loss_sum/iter_num)\n",
    "    recorder['mi'].append(mi_sum/iter_num)\n",
    "    \n",
    "    log_gen_outputs = np.concatenate(log_gen_outputs, axis=0)\n",
    "    log_gen_codes = np.concatenate(log_gen_codes, axis=0)\n",
    "    print(\"epoch: {}, D_loss: {}, G_loss: {}, MI = {}\".format(rep, D_loss_sum/iter_num, G_loss_sum/iter_num, mi_sum/iter_num))\n",
    "    print(\"좌표값 평균 = \", np.mean(log_gen_outputs[:,0]), np.mean(log_gen_outputs[:,1]))\n",
    "    c_gen = np.corrcoef(log_gen_outputs[:,0], log_gen_outputs[:,1])[0,1]\n",
    "    \n",
    "    print(\"corr = \", \"진짜 corr = \",c_gen, c_target)\n",
    "    recorder['corr'].append(c_gen)\n",
    "    \n",
    "    df = pd.DataFrame({'x': log_gen_outputs[:, 0], 'y': log_gen_outputs[:, 1]})\n",
    "    for i in range(code_qubits):\n",
    "        df[f'code{i}']=log_gen_codes[:, i]\n",
    "    corr_mat = df.corr().to_numpy()\n",
    "    for i in range(code_qubits):\n",
    "        recorder[f'code{i}-x'].append(corr_mat[0, i+2])\n",
    "        recorder[f'code{i}-y'].append(corr_mat[1, i+2])\n",
    "    \n",
    "    visualize_output(log_gen_outputs, log_gen_codes, title, rep, recorder)\n",
    "\n",
    "    if rep % 10 == 0:\n",
    "        with open(f'result/{title}/discriminator_{rep}.pkl', 'wb') as file:\n",
    "            pickle.dump(discriminator, file)\n",
    "        with open(f'result/{title}/generator_{rep}.pkl', 'wb') as file:\n",
    "            pickle.dump(generator_params, file)\n",
    "\n",
    "    final_rep = rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 지표 엑셀파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "df = pd.DataFrame(recorder)\n",
    "output_filename = f'result/{title}/recorder.xlsx'\n",
    "df.to_excel(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 결과 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for i in tqdm(range(5000)):\n",
    "    with torch.no_grad():\n",
    "        z = np.random.uniform(-1, 1, (1, n_qubits, 1))\n",
    "        code_input = z[:, -code_qubits:].reshape(code_qubits) # 입력 z중에서 code를 추출한다.\n",
    "        generator_output = generator_forward(generator_params, z, copula=output_copula)\n",
    "        generator_output = generator_output.cpu().numpy().reshape(2)\n",
    "        outputs.append(generator_output)\n",
    "        inputs.append(code_input)\n",
    "\n",
    "inputs = np.array(inputs).reshape(-1, code_qubits)\n",
    "\n",
    "for code_ind in range(code_qubits):\n",
    "    outputs = np.array(outputs)\n",
    "    plt.scatter(outputs[:, 0], outputs[:, 1], c=inputs[:, code_ind], cmap='RdYlBu', alpha=0.2)\n",
    "    plt.colorbar()  # 색상 막대 추가\n",
    "    plt.title(f'code{code_ind}-distribution (rep = {final_rep})')\n",
    "    plt.savefig(f'result/{title}/code_{code_ind}_{final_rep}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.array(outputs)[:len(x)]\n",
    "plt.scatter(outputs[:, 0], outputs[:, 1], s=17, alpha=0.1)\n",
    "plt.xlim(-0.1, 0.1)\n",
    "plt.ylim(-0.1, 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'x': outputs[:,0], 'y': outputs[:,1]}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.array(outputs)\n",
    "plt.scatter(x[:, 0], x[:, 1], s=17, alpha=0.1)\n",
    "plt.xlim(-0.1, 0.1)\n",
    "plt.ylim(-0.1, 0.1)\n",
    "plt.show()\n",
    "pd.DataFrame({'x': x[:,0], 'y': x[:,1]}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
